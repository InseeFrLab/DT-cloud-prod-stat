<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>index – DT Cloud &amp; Production Statistique</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../src/mlops/index.html" rel="next">
<link href="../../src/principles/index.html" rel="prev">
<link href="../../images/favicon.ico" rel="icon">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-44d8862ff5335838008e1d1029e4056f.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../styles/styles.css">
</head>

<body class="nav-sidebar docked slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../src/implementation/index.html">3 - Implémentation</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-center sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../../">DT Cloud &amp; Production Statistique</a> 
        <div class="sidebar-tools-main">
    <a href="../../dt-cloud-prod-stat.pdf" title="PDF" class="quarto-navigation-tool px-1" aria-label="PDF"><i class="bi bi-file-pdf-fill"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../src/introduction/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1 - Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../src/principles/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">2 - Principes</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../src/implementation/index.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">3 - Implémentation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../src/mlops/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">4 - MLOps</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../src/discussion/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">5 - Discussion</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#sec-implementation-fr" id="toc-sec-implementation-fr" class="nav-link active" data-scroll-target="#sec-implementation-fr"><span class="header-section-number">3</span> Un projet <em>open source</em> pour faciliter l’adoption des technologies <em>cloud</em></a>
  <ul class="collapse">
  <li><a href="#rendre-les-technologies-cloud-accessibles-aux-statisticiens" id="toc-rendre-les-technologies-cloud-accessibles-aux-statisticiens" class="nav-link" data-scroll-target="#rendre-les-technologies-cloud-accessibles-aux-statisticiens"><span class="header-section-number">3.1</span> Rendre les technologies <em>cloud</em> accessibles aux statisticiens</a></li>
  <li><a href="#sec-principles-autonomy-fr" id="toc-sec-principles-autonomy-fr" class="nav-link" data-scroll-target="#sec-principles-autonomy-fr"><span class="header-section-number">3.2</span> Des choix architecturaux visant à favoriser l’autonomie</a></li>
  <li><a href="#sec-catalog" id="toc-sec-catalog" class="nav-link" data-scroll-target="#sec-catalog"><span class="header-section-number">3.3</span> Un catalogue de services qui couvre le cycle de vie complet des projets de <em>data science</em></a></li>
  <li><a href="#sec-instances" id="toc-sec-instances" class="nav-link" data-scroll-target="#sec-instances"><span class="header-section-number">3.4</span> Construire des communs numérique : un projet, plusieurs instances</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="sec-implementation-fr" class="level1 page-columns page-full" data-number="3">
<h1 data-number="3"><span class="header-section-number">3</span> Un projet <em>open source</em> pour faciliter l’adoption des technologies <em>cloud</em></h1>
<p>Notre revue de la littérature et de l’évolution de l’écosystème de la donnée mettent en évidence les technologies <em>cloud</em>, en particulier la conteneurisation et le stockage objet, comme des éléments clés pour construire une plateforme de <em>data science</em> à la fois scalable et flexible. Néanmoins, les arguments qui justifient d’investir dans ce type d’infrastructure en tant qu’organisation ne suffisent pas à eux seuls à garantir leur adoption dans les pratiques. Cette section revient sur la genèse et le développement d’Onyxia, un projet développé à l’Insee qui vise à démocratiser l’accès aux technologies <em>cloud</em> en fournissant aux statisticiens des environnements de <em>data science</em> prêts à l’emploi qui favorisent l’expérimentation. Enfin, nous montrons comment les principes fondamentaux qui sous-tendent le projet Onyxia — innovation ouverte, licence <em>open-source</em>, absence d’enfermement propriétaire — s’inscrit dans une volonté de construire des communs numériques (“<em>commons</em>”) facilement réutilisables par les organisations. Ces principes ont permis le développement du projet à la fois à l’Insee et en dehors de l’Insee, avec plusieurs instances en production et de nombreuses autres à l’essai.</p>
<section id="rendre-les-technologies-cloud-accessibles-aux-statisticiens" class="level2 page-columns page-full" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="rendre-les-technologies-cloud-accessibles-aux-statisticiens"><span class="header-section-number">3.1</span> Rendre les technologies <em>cloud</em> accessibles aux statisticiens</h2>
<p>En marge de la conférence NTTS organisée en 2017 par Eurostat, un <em>hackathon</em> “<em>big data</em>” propose aux équipes de différents INS d’exploiter des offres d’emploi en ligne pour réfléchir aux problèmes d’adéquation entre l’offre et la demande de compétences sur le marché du travail à un niveau régional. Une équipe regroupant des agents de la DMCSI et de la DSI se constitue pour appréhender ces données à la fois volumineuses et peu structurées. Très vite, l’infrastructure de <em>self</em> à disposition — la première version d’AUS — montre ses limites. D’une part, l’infrastructure n’est alors pas dimensionnée pour gérer la volumétrie des données à traiter. Mais plus fondamentalement, c’est le manque d’autonomie qui se révèle le plus contraignant dans ce contexte. La plateforme de calcul impose l’utilisation des environnements <code>R</code> mis à disposition des statisticiens et ne permet pas l’installation immédiate de nouvelles librairies, là où la nature même d’un <em>hackathon</em> impose une grande flexibilité et la capacité de mobiliser de nouveaux outils rapidement. Finalement, la composition mixte statistique/informatique de l’équipe permet la mobilisation de ressources de calcul autres, permettant à l’équipe Insee d’obtenir la deuxième place du <em>hackathon</em>. Au-delà de l’anecdote, cet évènement illustre l’intrication croissante des dimensions méthodologiques et informatiques dans le paradigme de la <em>data science</em>, et amène la DSI à s’interroger quant à la manière de redonner de l’autonomie aux statisticiens dont le métier évolue vers des pratiques plus coûteuses en ressources. Ces réflexions se matérialisent rapidement grâce à une double opportunité : une nouvelle technologie de rupture — les technologies <em>cloud</em> — qui se montre adaptée au enjeux de la <em>data science</em> et la récupération de serveurs décommissionnés à la Direction Générale de l’Insee. Cette initiative aboutit à la mise en place en 2017 d’une première plateforme de conteneurisation dans les locaux de l’Insee, une “plateforme innovation” qui préfigure le SSP Cloud (cf. <a href="#sec-instances" class="quarto-xref">Section&nbsp;3.4</a>).</p>
<p>Cependant, les premières expérimentations révèlent un obstacle majeur à l’adoption généralisée des technologies <em>cloud</em> : la complexité de leur intégration dans un système d’information. Les infrastructures <em>cloud</em> sont par nature modulaires, faites de différents composants faiblement couplés. C’est précisément cette modularité qui favorise le passage à l’échelle et l’évolutivité de ces architectures. Cette modularité a néanmoins une contrepartie importante : la nécessité de configurer finement ces différents composants pour leur permettre de communiquer entre eux. Ainsi, un simple service RStudio lancé sur le <em>cluster</em> ne suffit pas en soi, il doit pouvoir communiquer avec la couche de stockage des données, le service de gestion des secrets, d’autres services éventuels permettant par exemple l’ordonnancement des traitements, etc. Ces configurations sont complexes et nombreuses et ne sauraient être demandées aux statisticiens désireux de bénéficier des avantages des infrastructures <em>cloud</em> dans le cadre de leurs traitements.</p>
<p>Ce constat est capital : choisir des technologies qui favorisent l’autonomie ne suffit pas à atteindre cet objectif si leur complexité constitue une barrière trop importante à leur adoption dans l’organisation. Ces dernières années, les statisticiens de l’Insee ont déjà dû s’adapter à un environnement en forte évolution en ce qui concerne leurs outils quotidiens : passer de logiciels propriétaires (SAS) à des outils open source (R, Python), s’approprier des technologies qui améliorent la reproductibilité (contrôle de version avec Git), consommer voire développer des API, etc. Ces changements, qui tendent à rapprocher la nature de leur travail de celui des développeurs informatiques, impliquent déjà des efforts considérables en termes de formation et des modifications substantielles des pratiques. Dans ce contexte, l’adoption des technologies <em>cloud</em> dans le cadre de la modernisation du <em>self</em> et, par là, l’opportunité pour l’organisation d’en tirer les bénéfices attendus, dépend fortement de notre capacité à les rendre accessibles.</p>
<div id="fig-onyxia-components" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-onyxia-components-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../../figures/onyxia-components.svg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-onyxia-components-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Onyxia agit comme un “liant” technique entre des composants <em>cloud native</em>
</figcaption>
</figure>
</div>
<p>C’est dans ce contexte que s’inscrit le développement du projet Onyxia, une application légère qui agit essentiellement comme une interface entre les composants modulaires qui composent l’architecture (voir <a href="#fig-onyxia-components" class="quarto-xref">Figure&nbsp;1</a>). Le point d’entrée principal pour l’utilisateur est une application web ergonomique<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> qui permet de lancer des services à partir d’un catalogue de <em>data science</em> (voir <a href="#sec-catalog" class="quarto-xref">Section&nbsp;3.3</a>)<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>. Ces services sont alors immédiatement déployés sous forme de conteneurs sur un <em>cluster</em> Kubernetes sous-jacent. Le lien entre l’interface utilisateur (UI) et Kubernetes est assurée par une API <a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>, dont le rôle est de transformer la demande de lancement de service de l’utilisateur en un ensemble de manifestes nécessaires pour déployer les ressources Kubernetes nécessaires à ce service. Pour une application donnée, ces ressources sont regroupées sous la forme d’un <em>chart</em> Helm<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>, une librairie largement utilisée pour empaqueter des applications potentiellement complexes sur Kubernetes <span class="citation" data-cites="gokhale2021creating">(<a href="#ref-gokhale2021creating" role="doc-biblioref">Gokhale et al. 2021</a>)</span> et gérer le cycle de vie de ces objets vivants.</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;<a href="https://github.com/InseeFrLab/onyxia">https://github.com/InseeFrLab/onyxia</a></p></div><div id="fn2"><p><sup>2</sup>&nbsp;<a href="https://github.com/InseeFrLab/images-datascience">https://github.com/InseeFrLab/images-datascience</a></p></div><div id="fn3"><p><sup>3</sup>&nbsp;<a href="https://github.com/InseeFrLab/onyxia-api">https://github.com/InseeFrLab/onyxia-api</a></p></div><div id="fn4"><p><sup>4</sup>&nbsp;<a href="https://github.com/InseeFrLab/helm-charts-interactive-services">https://github.com/InseeFrLab/helm-charts-interactive-services</a></p></div></div><p>Cette capacité à mettre à disposition des services prêts à l’emploi et ainsi d’abstraire à l’utilisateur la complexité des technologies <em>cloud</em> sous-jacentes est véritablement la valeur ajoutée du projet Onyxia. Bien que les utilisateurs puissent configurer un service pour l’adapter à leurs besoins, la plupart du temps, ils se contentent de lancer un service prêt à l’emploi avec des paramètres par défaut et commencent à développer immédiatement. En injectant automatiquement les informations d’authentification et de configuration dans les conteneurs lors de leur initialisation, Onyxia permet aux utilisateurs d’interagir sans difficulté avec les données de leur <em>bucket</em> sur MinIO, leurs informations sensibles (jetons, mots de passe) contenues dans un outil de gestion des secrets tel que Vault, etc. Cette injection automatique, associée à la pré-configuration des environnements de <em>data science</em> mis à disposition dans le catalogue d’images pour couvrir la plupart des usages courants de <em>data science</em>, permet aux utilisateurs d’exécuter des applications potentiellement complexes — comme des calculs distribués avec Spark sur Kubernetes à l’aide de données volumineuses stockées sur MinIO, ou encore l’entraînement de modèles d’apprentissage profond nécessitant un GPU — sans se heurter aux difficultés techniques liées à la configuration des composants nécessaires.</p>
</section>
<section id="sec-principles-autonomy-fr" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="sec-principles-autonomy-fr"><span class="header-section-number">3.2</span> Des choix architecturaux visant à favoriser l’autonomie</h2>
<p>Le projet Onyxia repose sur quelques principes structurants, avec un thème central : favoriser l’autonomie, à plusieurs niveaux. Ce principe s’applique d’abord au niveau de l’organisation, en évitant l’enfermement propriétaire. Afin d’obtenir un avantage concurrentiel, une pratique courante que de nombreux fournisseurs de <em>cloud</em> commerciaux développent est d’imposer l’utilisation de certaines applications ou protocoles pour accéder aux ressources <em>cloud</em>. Souvent, ces dernières ne sont néanmoins pas interopérables : les scripts et pratiques qui fonctionnent avec un fournisseur ne marcheront pas à l’identique avec un autre, compliquant considérablement les migrations potentielles vers une autre plateforme <em>cloud</em> <span class="citation" data-cites="opara2016critical">(<a href="#ref-opara2016critical" role="doc-biblioref">Opara-Martins, Sahandi, and Tian 2016</a>)</span>. Face à ce constat, une tendance émerge vers l’adoption de stratégies dites “neutres” vis-à-vis des hébergeurs <em>cloud</em> afin de réduire la dépendance aux solutions spécifiques d’un seul fournisseur <span class="citation" data-cites="opara2017holistic">(<a href="#ref-opara2017holistic" role="doc-biblioref">Opara-Martins, Sahandi, and Tian 2017</a>)</span>. Dans cette optique, l’utilisation d’Onyxia est pensée de manière à être intrinsèquement non enfermante : lorsqu’une organisation choisit de l’utiliser, elle choisit les technologies sous-jacentes — la conteneurisation et le stockage d’objets — mais pas la solution en elle-même. Le logiciel Onyxia peut être déployé sur n’importe quel cluster Kubernetes, qu’il soit <em>on-premise</em>, c’est-à-dire installé et géré par l’organisation sur ses propres serveurs, ou issu d’une offre proposée par des hébergeurs <em>clouds</em> commerciaux. De même, le choix de MinIO comme solution de stockage contribue à limiter l’enfermement propriétaire. En effet, MinIO est d’une part une solution de stockage objet <em>open source</em>, et d’autre part une solution basée sur l’API S3 d’Amazon, qui est progressivement devenu un standard de l’écosystème de la donnée. Ainsi, dans la mesure où les stockages proposés par les divers fournisseurs de <em>cloud</em> (AWS, GCP, etc.) s’assurent de leur compatibilité avec cette API, ces choix favorisent une position agnostique qui facilite toute migration ultérieure vers une solution <em>cloud</em> différente.</p>
<p>La volonté du projet Onyxia de favoriser l’autonomie s’illustre également au niveau du choix des services. Les logiciels propriétaires qui ont été intensivement utilisé dans les statistiques publiques et la recherche — comme SAS ou STATA — induisent également un phénomène d’enfermement propriétaire. Les coûts des licences, substantiels, peuvent évoluer rapidement et ce dans un contexte de marges de négociation réduites pour l’organisation si son système d’information dépend de manière sensible du code propriétaire. Par ailleurs, si ces logiciels ont l’avantage de mettre à disposition des utilisateurs des procédures statistiques faciles d’utilisation et stables dans la durée, elles contraignent dans le même temps à un ensemble de procédures proposées et maintenues par l’entreprise et limitent donc l’appropriation des nouveaux outils produits par l’écosystème. Par ailleurs, la nature fermée de leur code source empêche d’auditer certaines des procédures en question. A l’inverse, les choix réalisés dans le projet Onyxia visent à minimiser au maximum l’effet d’enfermement des pratiques. D’abord, en n’incluant dans son catalogue que des services <em>open-source</em>, Onyxia promeut des logiciels dont il est possible d’auditer le code, ce qui favorise la transparence et la reproductibilité des statistiques produites. Si le catalogue des services offerts est par nature limité, le choix de ces derniers est également transparent : les services proposés doivent être standards, <em>open source</em> et s’intégrer avec Kubernetes ; le catalogue est par ailleurs lui-même ouvert à de nouvelles demandes ou des contributions. Enfin, plus fondamentalement, Onyxia limite l’enfermement propriétaire en étant conçu de sorte à être amovible. L’objectif final est d’améliorer la familiarité et le confort des utilisateurs avec les technologies <em>cloud</em> sous-jacentes et les services standards de <em>data science</em>, de sorte à ce qu’ils puissent continuer à utiliser ces services si une autre infrastructure était adoptée. Un exemple illustratif de cette philosophie est l’approche de la plateforme concernant les actions des utilisateurs : pour les tâches effectuées via l’interface, comme le lancement d’un service ou la gestion des données, l’interface affiche les commandes équivalentes dans le terminal (Linux), promouvant ainsi une compréhension fine de ce qui est effectivement exécuté sur le <em>cluster</em> lors de la réalisation d’une action par l’utilisateur (voir <a href="#fig-service-configuration" class="quarto-xref">Figure&nbsp;2</a>).</p>
<div id="fig-service-configuration" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-service-configuration-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../../figures/service-configuration.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-service-configuration-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Lancer un service via l’interface web d’Onyxia.
</figcaption>
</figure>
</div>
<p>Note: Les services du catalogue d’Onyxia peuvent être utilisés tels quels (“*out-of-the-box”) ou configurés par les utilisateurs pour répondre à leurs besoins spécifiques. Afin de limiter la dépendance des utilisateurs vis-à-vis d’Onyxia, chaque action effectuée par l’utilisateur via l’interface utilisateur est accompagnée de la commande exacte exécutée sur le cluster Kubernetes sous-jacent.</p>
<p>Si le projet Onyxia a été initialement développé afin de permettre l’expérimentation avec des outils de <em>data science</em> à l’état de l’art, les environnements qu’il met à disposition se veulent pour autant généralistes. Un objectif majeur du projet est de couvrir une large gamme de besoins exprimés par les statisticiens, de la production statistique courante réalisée en <em>self</em> aux usages les plus expérimentaux. Ainsi, cohabitent dans le catalogue de services des environnements de développement usuels — RStudio pour l’usage de R, Jupyter et VSCode pour l’usage de Python — et des environnements pour des usages avancés, mais déployés à travers les mêmes environnements interactifs. Par exemple, lancer des traitements distribués avec Spark en Python se fera également à travers l’usage de Jupyter ou VSCode ; les services de base peuvent ainsi servir de porte d’entrée à des usages plus avancés par la suite. Du fait de la diversité des besoins couverts, les bénéfices à migrer seront différenciés selon les profils. Les utilisateurs dont les besoins actuels sont déjà bien couverts par les infrastructures de <em>self</em> existantes bénéficieront de la capacité à spécifier finement les ressources allouées à leur service et ainsi limiter les risques de rentrer en concurrence avec les processus d’autres utilisateurs en cas de saturation de la machine. Les bénéfices à migrer seront davantage marqués pour les utilisateurs souhaitant aller plus loin et développer de véritables prototypes d’applications pour leurs projets : configurer des scripts d’initialisation pour adapter les environnements à leurs besoins, déployer une application interactive (par exemple, en R Shiny) pour publier des visualisations de données dynamiques, ou encore déployer des services sur-mesure comme des bases de données à la demande ou bien des prototypes d’API. Pour permettre à ces utilisateurs avancés, souvent limités par la rigidité des environnements de calculs traditionnels, de continuer à faire progresser la structure via des usages innovants, Onyxia offre — selon la politique de sécurité de l’organisation — de larges possibilités de configuration des services et un accès étendu au cluster Kubernetes sous-jacent. Cela signifie que les utilisateurs peuvent ouvrir librement un terminal sur un service interactif et interagir avec le cluster — dans les limites de leur <em>namespace</em> — afin d’appliquer des ressources personnalisées et déployer des applications ou d’autres usages de leurs choix.</p>
<p>Au-delà de l’autonomie et de la scalabilité, les choix architecturaux d’Onyxia favorisent également la reproductibilité des calculs statistiques et la portabilité des applications. Dans le paradigme des conteneurs, l’utilisateur doit apprendre à gérer des ressources qui sont par nature éphémères, puisqu’elles n’existent qu’au moment de leur mobilisation effective dans le cadre d’un traitement. Cette non-persistance implique une séparation claire du code — hébergé sur une forge de code, comme GitLab ou GitHub — des données — stockées sur une solution de stockage spécifique, comme MinIO — et de la configuration et des secrets — passés au conteneur sous la forme de variables d’environnement. Par construction, un conteneur exécuté à partir d’un même ensemble d’<em>inputs</em> produit les mêmes <em>outputs</em> (application déployée, mise à disposition d’un jeu de données, modification d’une table de données, etc.). Cette séparation est un critère fondamental de qualité des projets de code dans la mesure où elle favorise à la fois la reproductibilité et de portabilité. Un conteneur étant nécessairement identifié par un <em>tag</em> (label), il est possible dans ce paradigme de versionner non plus seulement le code d’un projet, mais l’ensemble de l’environnement d’exécution qui garantit la reproduction des résultats obtenus à partir des mêmes données en entrée, ce qui constitue un gage de reproductibilité du chiffre statistique.</p>
<p>Conséquence de leur inhérente reproductibilité, les conteneurs permettent de garantir la portabilité des projets, c’est-à-dire leur capacité à s’exécuter de manière homogène quelle que soit l’infrastructure de calcul sous-jacente. Cette propriété essentielle permet de comprendre pourquoi la conteneurisation est devenue une technologie aussi centrale lorsqu’on s’intéresse au sujet de la mise en production, et en particulier aux coûts que cette étape peut engendrer dans le cycle de vie d’un projet. Traditionnellement, les statisticiens développent des <em>batchs</em> et/ou des applications sur une infrastructure <em>self</em>, généralement bien dotée en puissance de calcul et fournissant des environnements pré-configurés pour des usages statistiques courants. Une fois cette phase effectuée, les scripts sont livrés aux équipes informatiques pour être déployés sur une infrastructure de production, potentiellement très différente de l’infrastructure de <em>self</em> — par exemple, les serveurs d’AUSv3 fonctionnent sous Windows là où les machines virtuelles de production de l’Insee fonctionnent sous Linux. Ainsi, il est courant que les équipes informatiques, pour assurer le déploiement en production, doivent résoudre un ensemble de problèmes — librairies systèmes manquantes, différentes version de R installées, incompatibilité des versions entre packages, etc — et ce dans un langage statistique qu’ils n’utilisent pas au quotidien. Cette situation, conséquence de l’écart existant entre les environnements de développement et de production, génère dans le meilleurs des cas des coûts de débogage et de coordination, et dans le pire des cas des coûts substantiels de redéveloppement des applications dans un langage informatique, mieux maîtrisé et adapté à l’environnement de production. De ce point de vue, la conteneurisation porte un potentiel considérable : celui de réduire au minimum les coûts de la phase de mise en production en redéfinissant le partage des rôles entre statisticiens et informaticiens. Dans un mode de fonctionnement où le livrable échangé n’est plus simplement le code mais l’image (conteneurisée), c’est-à-dire non seulement le code mais également tout l’environnement qui permet de le faire tourner correctement, l’écart dans les langages pratiqués par les différentes équipes présente beaucoup moins d’importance. En livrant une image testée dans son environnement de développement <em>self</em>, le statisticien garantit le bon fonctionnement de l’application et les coûts liés aux différences d’environnement et les coûts de coordination potentiels sont considérablement réduits. Ainsi, ce mode d’organisation permet d’envisager des modes de collaboration plus continus entre les différentes équipes : la spécification, l’écriture de la logique métier, et le débogage éventuel côté équipe métier ; le développement applicatif, les tests fonctionnels, le déploiement et la supervision côté informatique.</p>
</section>
<section id="sec-catalog" class="level2 page-columns page-full" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="sec-catalog"><span class="header-section-number">3.3</span> Un catalogue de services qui couvre le cycle de vie complet des projets de <em>data science</em></h2>
<p>L’intention du projet Onyxia est de fournir aux statisticiens un environnement complet conçu pour accompagner le développement de bout en bout des projets de <em>data science</em>. Comme illustré dans <a href="#fig-onyxia-catalog" class="quarto-xref">Figure&nbsp;3</a>, le catalogue par défaut propose une vaste gamme de services couvrant l’ensemble du cycle de vie d’un projet, du développement à la diffusion.</p>
<div id="fig-onyxia-catalog" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-onyxia-catalog-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../../figures/onyxia-catalog.svg" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-onyxia-catalog-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: Le catalogue d’Onyxia vise à couvrir l’ensemble du cycle de vie des projets de data science
</figcaption>
</figure>
</div>
<p>L’utilisation principale de la plateforme est le déploiement d’environnements de développement interactifs (IDE), tels que RStudio, Jupyter ou VSCode. Ces IDE sont voulus comme étant “prêts à l’emploi” : ils sont équipés des dernières versions des principaux langages de programmation <em>open source</em> couramment utilisés par les statisticiens publics (R, Python, SQL, Julia) ainsi que des librairies les plus fréquemment utilisées pour chaque langage. Afin de garantir que les services restent à jour et cohérents entre eux, l’Insee maintient un dépôt d’images Docker sous-jacentes et les met à jour chaque semaine. Ces images sont entièrement <em>open source</em><a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a> et peuvent donc être réutilisée en dehors du projet.</p>
<div class="no-row-height column-margin column-container"><div id="fn5"><p><sup>5</sup>&nbsp;<a href="https://github.com/InseeFrLab/images-datascience">https://github.com/InseeFrLab/images-datascience</a></p></div></div><p>Comme décrit dans les sections précédentes, la couche de persistance de ces environnements interactifs est principalement assurée par MinIO, une solution de stockage objet <em>open source</em>. Cette solution étant basée sur une API REST standardisée, les fichiers peuvent être facilement interrogés depuis R ou Python à l’aide de librairies de haut niveau. Cela représente en soi une étape importante pour garantir la reproductibilité : les données ne sont pas sauvegardées localement, puis appelées via des chemins propres à une infrastructure ou un système de fichiers particulier. Au contraire, les requêtes aux fichiers sont spécifiées sous forme de requêtes HTTP standards, rendant la structure globale des projets plus évolutive. Les traitements rencontrés dans le service statistique public reposant très largement sur des fichiers de données, le paradigme du stockage objet répond très bien aux besoins de la plupart des projets statistiques déployés sur ces infrastructures. Des services de bases de données supplémentaires, tels que PostgreSQL et MongoDB, sont également proposés pour les applications ayant des besoins spécifiques, notamment celles nécessitant de traitement géospatial en base (PostGIS) ou un stockage de données orienté documents.</p>
<p>Onyxia ayant été développé afin de permettre l’expérimentation avec des sources de données volumineuses, le catalogue propose également des services facilitant le passage à l’échelle. Pour les projets faisant intervenir des données volumineuses — de l’ordre de dizaines ou de centaines de millions de ligne — les différents services disposent nativement des librairies Arrow et DuckDB, permettant de traiter efficacement les données stockées au format Parquet en mémoire. Pour des usages plus conséquents, faisant intervenir des données massives, des logiciels comme Spark et Trino permettent d’effectuer des calculs distribués au sein d’un cluster Kubernetes via un simple lancement de service interactif ou d’un <em>batch</em> de traitement. Dans les deux cas, ces services sont préconfigurés pour s’intégrer naturellement avec le stockage S3, facilitant ainsi la création de <em>pipelines</em> de données à la fois efficients et intégrés de bout en bout. Enfin, différents services pré-configurés pour l’utilisation d’une GPU sont également proposés pour les projets basés sur des méthodes d’apprentissage automatique intensives en calcul. Le catalogue d’Onyxia fournit donc un point d’entrée unique pour mettre à disposition ces ressources rares ainsi que des librairies spécialisées — par exemple, les librairies de <em>deep learning</em> PyTorch et Tensorflow — avec la même simplicité que le lancement d’un service interactif de base.</p>
<p>Au-delà de la phase expérimentation, l’objectif est également de permettre aux statisticiens de produire des projets dits de “quasi-prod”, au sens où ils préfigurent un passage en production afin d’en faciliter sa réalisation. Conformément aux principes de l’approche <em>DevOps</em>, cela implique de faciliter le déploiement de prototypes et leur amélioration continue au fil du temps. À cette fin, le catalogue d’Onyxia propose un ensemble de services <em>open source</em> visant à automatiser et industrialiser le processus de déploiement d’applications (ArgoCD), ordonnancer des traitements séquentiels et/ou parallèles (Argo-Workflows), ou encore déployer et gérer le cycle de vie des modèles d’apprentissage automatique (MLflow). La <a href="../../src/mlops/index.html#sec-mlops">Section 4</a> illustre comment ces outils ont joué un rôle central dans la mise en production de premiers modèles d’apprentissage automatique à l’Insee, conformément aux principes du MLOps.</p>
<p>Dans la <a href="#sec-principles-autonomy-fr" class="quarto-xref">Section&nbsp;3.2</a>, nous avons souligné qu’un des principes fondamentaux d’Onyxia était d’éviter l’enfermement propriétaire. Dans cette optique, les organisations qui instancient Onyxia sont libres de personnaliser les catalogues pour répondre à leurs besoins spécifiques, ou même de créer leurs propres catalogues indépendamment de l’offre par défaut. Cette flexibilité garantit aux organisations le fait de ne pas être limité à une solution ou à un fournisseur unique, et ainsi de pouvoir adapter la plateforme à l’évolution de leurs besoins ou de migrer vers une autre solution <em>cloud</em> dans le futur si nécessaire.</p>
</section>
<section id="sec-instances" class="level2 page-columns page-full" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="sec-instances"><span class="header-section-number">3.4</span> Construire des communs numérique : un projet, plusieurs instances</h2>
<p>En tant qu’initiative entièrement <em>open source</em>, le logiciel Onyxia vise à construire des “communs numériques” en promouvant et en développant des logiciels facilement réutilisables dans le service statistique publique et plus largement <span class="citation" data-cites="schweik2006free">(<a href="#ref-schweik2006free" role="doc-biblioref">Schweik 2006</a>)</span>. Cela concerne, tout d’abord, les composants sur lesquels repose Onyxia : à la fois ses briques technologiques (Kubernetes, MinIO, Vault) de même que l’ensemble des services du catalogue sont <em>open source</em>. De même, le code source d’Onyxia est disponible publiquement sur GitHub<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a> sous licence MIT ce qui, associé à une documentation détaillée<a href="#fn7" class="footnote-ref" id="fnref7" role="doc-noteref"><sup>7</sup></a>, favorise les réutilisations du projet. Enfin, cette orientation est sensible à travers les principes architecturaux qui ont guidé le développement du projet. La notion de “région”, qui permet de paramétriser finement la configuration du logiciel et son interaction avec le cluster Kubernetes sous-jacent, la possibilité de définir simplement des identités graphiques spécifiques (voir <a href="#fig-onyxia-instances" class="quarto-xref">Figure&nbsp;4</a>), et la possibilité d’adapter la catalogue de services (cf.&nbsp;supra) facilitent les ré-instanciations et l’appropriation du projet par les organisations.</p>
<div class="no-row-height column-margin column-container"><div id="fn6"><p><sup>6</sup>&nbsp;<a href="https://github.com/InseeFrLab/onyxia">https://github.com/InseeFrLab/onyxia</a></p></div><div id="fn7"><p><sup>7</sup>&nbsp;<a href="https://docs.onyxia.sh/">https://docs.onyxia.sh/</a></p></div></div><div id="fig-onyxia-instances" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-onyxia-instances-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../../figures/onyxia-instances.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-onyxia-instances-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: Un projet, de multiples instances : l’interface web est adaptable à l’identité graphique de chaque organisation
</figcaption>
</figure>
</div>
<p>En 2025, deux instances d’Onyxia cohabitent à l’Insee, couvrant chacune des besoins différents. L’instance historique, nommée SSP Cloud, est l’instance “vitrine” du projet Onyxia. Équipée de ressources de calcul conséquentes<a href="#fn8" class="footnote-ref" id="fnref8" role="doc-noteref"><sup>8</sup></a> et du catalogue de services le plus complet, cette plateforme est conçue comme un bac à sable permettant d’expérimenter en toute autonomie des nouvelles méthodes et outils de <em>data science</em> <span class="citation" data-cites="comte2022sspcloud">(<a href="#ref-comte2022sspcloud" role="doc-biblioref">Comte, Degorre, and Lesur 2022</a>)</span>. Au-delà de ses capacités techniques, le SSP Cloud incarne les principes de l’innovation ouverte <span class="citation" data-cites="chesbrough2003open">(<a href="#ref-chesbrough2003open" role="doc-biblioref">Chesbrough 2003</a>)</span>. Déployée sur internet<a href="#fn9" class="footnote-ref" id="fnref9" role="doc-noteref"><sup>9</sup></a>, la plateforme est accessible non seulement aux agents de l’Insee mais également, plus largement, aux agents des ministères et des collectivités, aux universités et grandes écoles françaises, et aux autres INS européens. La nature fondamentalement collaborative du SSP Cloud s’est avérée particulièrement adaptée à l’organisation d’événements innovants, tels que des <em>hackathons</em>, tant au niveau national qu’international. Il est devenu une ressource intégrale pour plusieurs universités et grandes écoles françaises, favorisant l’enseignement des technologies <em>cloud</em> tout en évitant l’effet d’enfermement propriétaire dû à une dépendance excessive des institutions éducatives envers des solutions <em>cloud</em> propriétaires. En conséquence, la plateforme est désormais largement utilisée dans le service statistique publique français et plus largement, avec environ 1000 utilisateurs uniques par mois. Ces utilisateurs forment une communauté dynamique grâce à un canal de discussion unique<a href="#fn10" class="footnote-ref" id="fnref10" role="doc-noteref"><sup>10</sup></a> ; ils contribuent à améliorer l’expérience utilisateur en signalant des <em>bugs</em>, en proposant de nouvelles fonctionnalités et en contribuant ainsi directement au projet.</p>
<div class="no-row-height column-margin column-container"><div id="fn8"><p><sup>8</sup>&nbsp;Sur le plan matériel, le SSP Cloud est constitué d’un cluster Kubernetes d’environ 20 serveurs, pour une capacité totale de 10 To de RAM, 1100 processeurs, 34 GPU et 150 To de stockage.</p></div><div id="fn9"><p><sup>9</sup>&nbsp;<a href="https://datalab.sspcloud.fr/">https://datalab.sspcloud.fr/</a></p></div><div id="fn10"><p><sup>10</sup>&nbsp;Lien vers les canaux de discussion : <a href="Canal Tchap du SSP Cloud">https://www.tchap.gouv.fr/#/room/#SSPCloudXDpAw6v:agent.finances.tchap.gouv.fr</a> et <a href="Canal Slack du projet Onyxia">https://join.slack.com/t/3innovation/shared_invite/zt-19tht9hvr-bZGMdW8AV_wvd5kz3wRSMw</a></p></div></div><p>Si le côté résolument ouvert du SSP Cloud rend cette instance particulièrement adaptée à la préfiguration de nouveaux usages, il impose en contrepartie l’utilisation de données ouvertes dans les projets qui y sont menés. A ce titre, cette instance ne pouvait servir de plateforme de traitements de données confidentielles à l’Insee. Pour pallier cette limite, les équipes de la DSI ont mis en place en 2025 une plateforme de calcul à la fois moderne — basée sur les technologies <em>cloud</em> présentées dans cet article : conteneurisation et stockage objet — et homologuée pour le traitement des données confidentielles. Nommée “LS³” — pour libre service “kube”, en référence au cluster Kubernetes sous-jacent — cette plateforme se positionne en complémentarité à AUSv3, avec pour ambition d’offrir un cadre de travail plus moderne pour les cas d’usage déjà correctement couverts et de répondre aux besoins fonctionnels aujourd’hui non ou mal couverts par cette dernière (déploiement d’applications interactive et de bases de données, calcul distribué, ordonnancement de traitements, etc.). Basée sur le logiciel Onyxia, la plateforme LS³ hérite des développements continus qui améliorent le projet, que ce soit sur l’interface utilisateur — par exemple, le développement d’un explorateur de données permettant de visualiser rapidement le contenu d’un fichier Parquet — où dans le catalogue de services, dont LS³ reprend les services les plus utilisés. A contrario, les retours des utilisateurs de plus en plus nombreux de cette plateforme permettent d’améliorer les composants d’Onyxia, bénéficiant à l’ensemble des instances déployées du projet.</p>
<p>La possibilité pour d’autres organisations de déployer leur propre instance interne d’Onyxia et de l’adapter à leurs besoins spécifiques (voir <a href="#fig-onyxia-instances" class="quarto-xref">Figure&nbsp;4</a>) a permis le développement du projet au delà de l’Insee. Des instances d’Onyxia sont désormais en production dans plusieurs organisations : INS (Statistique Norvège), ONG (Mercator Ocean<a href="#fn11" class="footnote-ref" id="fnref11" role="doc-noteref"><sup>11</sup></a>), et d’autres sont en phase d’expérimentation. La dimension d’innovation ouverte du projet renforce par ailleurs cette dynamique. Dans l’optique de faire du SSP Cloud une galerie de solutions innovantes, l’Office Fédéral de la Statistique suisse (FSO) a ajouté son outil de confidentialité différentielle Lomas <span class="citation" data-cites="aymon2024lomas">(<a href="#ref-aymon2024lomas" role="doc-biblioref">Aymon et al. 2024</a>)</span> au catalogue des services. La division statistique de l’ONU, dans le cadre de discussions autour du projet Lomas avec le FSO, a ainsi découvert le logiciel Onyxia et devrait l’adopter prochainement comme environnement de référence pour son projet de Global Platform<a href="#fn12" class="footnote-ref" id="fnref12" role="doc-noteref"><sup>12</sup></a>. Dans les prochaines années, l’implication des INS européens devrait par ailleurs se renforcer, le SSPCloud ayant été choisi comme plateforme de référence dans le cadre du projet AIML4OS<a href="#fn13" class="footnote-ref" id="fnref13" role="doc-noteref"><sup>13</sup></a>. Cette diffusion du logiciel Onyxia permet d’attirer une communauté croissante de contributeurs au projet <em>open-source</em>, favorisant une transition progressive vers une gouvernance plus décentralisée du projet.</p>



<div class="no-row-height column-margin column-container"><div id="fn11"><p><sup>11</sup>&nbsp;Lien vers l’instance Onyxia de Mercator Ocean : <a href="https://datalab.dive.edito.eu">https://datalab.dive.edito.eu</a></p></div><div id="fn12"><p><sup>12</sup>&nbsp;“Sous la gouvernance du Comité d’experts des Nations unies sur le Big Data et la Data Science pour les statistiques officielles (UN-CEBD), la Global Platform a construit un écosystème de services cloud pour soutenir la collaboration internationale dans le développement des statistiques officielles en utilisant de nouvelles sources de données et des méthodes innovantes et pour aider les pays à mesurer les Objectifs de développement durable (SDGs) afin de mettre en œuvre le Programme de Développement Durable à l’horizon 2030.” (<a href="https://unstats.un.org/bigdata/un-global-platform.cshtml">https://unstats.un.org/bigdata/un-global-platform.cshtml</a>)</p></div><div id="fn13"><p><sup>13</sup>&nbsp;Plus d’informations à propos de ce projet sont disponibles sur cette page : <a href="https://cros.ec.europa.eu/dashboard/aiml4os">https://cros.ec.europa.eu/dashboard/aiml4os</a></p></div></div></section>
</section>


<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-aymon2024lomas" class="csl-entry" role="listitem">
Aymon, Damien, Dan-Thuy Lam, Lancelot Marti, Pauline Maury-Laribière, Christine Choirat, and Raphaël de Fondeville. 2024. <span>“Lomas: A Platform for Confidential Analysis of Private Data.”</span> <em>arXiv Preprint arXiv:2406.17087</em>.
</div>
<div id="ref-chesbrough2003open" class="csl-entry" role="listitem">
Chesbrough, Henry William. 2003. <em>Open Innovation: The New Imperative for Creating and Profiting from Technology</em>. Harvard Business Press.
</div>
<div id="ref-comte2022sspcloud" class="csl-entry" role="listitem">
Comte, Frédéric, Arnaud Degorre, and Romain Lesur. 2022. <span>“SSPCloud: A Creative Factory to Support Experimentations in the Field of Official Statistics.”</span> <em>Courrier Des Statistiques, INSEE</em> 7: 68–85.
</div>
<div id="ref-gokhale2021creating" class="csl-entry" role="listitem">
Gokhale, Shivani, Reetika Poosarla, Sanjeevani Tikar, Swapnali Gunjawate, Aparna Hajare, Shilpa Deshpande, Sourabh Gupta, and Kanchan Karve. 2021. <span>“Creating Helm Charts to Ease Deployment of Enterprise Application and Its Related Services in Kubernetes.”</span> In <em>2021 International Conference on Computing, Communication and Green Engineering (CCGE)</em>, 1–5. IEEE.
</div>
<div id="ref-opara2017holistic" class="csl-entry" role="listitem">
Opara-Martins, Justice, M Sahandi, and Feng Tian. 2017. <span>“A Holistic Decision Framework to Avoid Vendor Lock-in for Cloud Saas Migration.”</span> <em>Computer and Information Science</em> 10 (3).
</div>
<div id="ref-opara2016critical" class="csl-entry" role="listitem">
Opara-Martins, Justice, Reza Sahandi, and Feng Tian. 2016. <span>“Critical Analysis of Vendor Lock-in and Its Impact on Cloud Computing Migration: A Business Perspective.”</span> <em>Journal of Cloud Computing</em> 5: 1–18.
</div>
<div id="ref-schweik2006free" class="csl-entry" role="listitem">
Schweik, Charles M. 2006. <span>“Free/Open-Source Software as a Framework for Establishing Commons in Science.”</span> Edited by Elinor Hess Charlotte &amp; Ostrom.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/inseefrlab\.github\.io\/DT-cloud-prod-stat\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      const annoteTargets = window.document.querySelectorAll('.code-annotation-anchor');
      for (let i=0; i<annoteTargets.length; i++) {
        const annoteTarget = annoteTargets[i];
        const targetCell = annoteTarget.getAttribute("data-target-cell");
        const targetAnnotation = annoteTarget.getAttribute("data-target-annotation");
        const contentFn = () => {
          const content = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          if (content) {
            const tipContent = content.cloneNode(true);
            tipContent.classList.add("code-annotation-tip-content");
            return tipContent.outerHTML;
          }
        }
        const config = {
          allowHTML: true,
          content: contentFn,
          onShow: (instance) => {
            selectCodeLines(instance.reference);
            instance.reference.classList.add('code-annotation-active');
            window.tippy.hideAll();
          },
          onHide: (instance) => {
            unselectCodeLines();
            instance.reference.classList.remove('code-annotation-active');
          },
          maxWidth: 300,
          delay: [50, 0],
          duration: [200, 0],
          offset: [5, 10],
          arrow: true,
          appendTo: function(el) {
            return el.parentElement.parentElement.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'quarto',
          placement: 'right',
          popperOptions: {
            modifiers: [
            {
              name: 'flip',
              options: {
                flipVariations: false, // true by default
                allowedAutoPlacements: ['right'],
                fallbackPlacements: ['right', 'top', 'top-start', 'top-end', 'bottom', 'bottom-start', 'bottom-end', 'left'],
              },
            },
            {
              name: 'preventOverflow',
              options: {
                mainAxis: false,
                altAxis: false
              }
            }
            ]        
          }      
        };
        window.tippy(annoteTarget, config); 
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../src/principles/index.html" class="pagination-link" aria-label="2 - Principes">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">2 - Principes</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../src/mlops/index.html" class="pagination-link" aria-label="4 - MLOps">
        <span class="nav-page-text">4 - MLOps</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>