---
number-offset: 2
---

# Un projet *open source* pour faciliter l'adoption des technologies *cloud* {#sec-implementation-fr}

Notre revue de la littérature et de l'évolution de l'écosystème de la donnée mettent en évidence les technologies *cloud*, en particulier la conteneurisation et le stockage objet, comme des éléments clés pour construire une plateforme de *data science* à la fois scalable et flexible. Néanmoins, les arguments qui justifient d'investir dans ce type d'infrastructure en tant qu'organisation ne suffisent pas à eux seuls à garantir leur adoption dans les pratiques. Cette section revient sur la genèse et le développement d'Onyxia, un projet développé à l’Insee qui vise à démocratiser l’accès aux technologies *cloud* en fournissant aux statisticiens des environnements de *data science* prêts à l'emploi qui favorisent l'expérimentation. Enfin, nous montrons comment les principes fondamentaux qui sous-tendent le projet Onyxia — innovation ouverte, licence *open-source*, absence d'enfermement propriétaire — s’inscrit dans une volonté de construire des communs numériques ("*commons*") facilement réutilisables par les organisations. Ces principes ont permis le développement du projet à la fois à l'Insee et en dehors de l'Insee, avec plusieurs instances en production et de nombreuses autres à l'essai.

## Rendre les technologies *cloud* accessibles aux statisticiens

En marge de la conférence NTTS organisée en 2017 par Eurostat, un *hackathon* "*big data*" propose aux équipes de différents INS d'exploiter des offres d'emploi en ligne pour réfléchir aux problèmes d'adéquation entre l’offre et la demande de compétences sur le marché du travail à un niveau régional. Une équipe regroupant des agents de la DMCSI et de la DSI se constitue pour appréhender ces données à la fois volumineuses et peu structurées. Très vite, l'infrastructure de *self* à disposition — la première version d'AUS — montre ses limites. D'une part, l'infrastructure n'est alors pas dimensionnée pour gérer la volumétrie des données à traiter. Mais plus fondamentalement, c'est le manque d'autonomie qui se révèle le plus contraignant dans ce contexte. La plateforme de calcul impose l'utilisation des environnements `R` mis à disposition des statisticiens et ne permet pas l'installation immédiate de nouvelles librairies, là où la nature même d'un *hackathon* impose une grande flexibilité et la capacité de mobiliser de nouveaux outils rapidement. Finalement, la composition mixte statistique/informatique de l'équipe permet la mobilisation de ressources de calcul autres, permettant à l'équipe Insee d'obtenir la deuxième place du *hackathon*. Au-delà de l'anecdote, cet évènement illustre l'intrication croissante des dimensions méthodologiques et informatiques dans le paradigme de la *data science*, et amène la DSI à s'interroger quant à la manière de redonner de l'autonomie aux statisticiens dont le métier évolue vers des pratiques plus coûteuses en ressources. Ces réflexions se matérialisent rapidement grâce à une double opportunité : une nouvelle technologie de rupture — les technologies *cloud* — qui se montre adaptée au enjeux de la *data science* et la récupération de serveurs décommissionnés à la Direction Générale de l'Insee. Cette initiative aboutit à la mise en place en 2017 d'une première plateforme de conteneurisation dans les locaux de l'Insee, une "plateforme innovation" qui préfigure le SSP Cloud (cf. @sec-instances).

Cependant, les premières expérimentations révèlent un obstacle majeur à l’adoption généralisée des technologies *cloud* : la complexité de leur intégration. Les infrastructures *cloud* sont par nature modulaires, faites de différents composants faiblement couplés. C'est précisément cette modularité qui favorise le passage à l'échelle et l'évolutivité de ces architectures. Cette modularité a néanmoins une contrepartie importante : la nécessité de configurer finement ces différents composants pour leur permettre de communiquer entre eux. Ainsi, un simple service RStudio lancé sur le *cluster* ne suffit pas en soi : il doit pouvoir communiquer avec la couche de stockage des données, le service de gestion des secrets, d'autres services éventuels permettant par exemple l'ordonnancement des traitements, etc. Ces configurations sont complexes et nombreuses et ne sauraient être demandées aux statisticiens désireux de bénéficier des avantages des infrastructures *cloud* dans le cadre de leurs traitements.

Ce constat est capital : choisir des technologies qui favorisent l’autonomie ne suffit pas à atteindre cet objectif si leur complexité constitue une barrière trop importante à leur adoption dans l’organisation. Ces dernières années, les statisticiens de l’Insee ont déjà dû s’adapter à un environnement en forte évolution en ce qui concerne leurs outils quotidiens : passer de logiciels propriétaires (SAS) à des outils open source (R, Python), s’approprier des technologies qui améliorent la reproductibilité (contrôle de version avec Git), consommer voire développer des API, etc. Ces changements, qui tendent à rapprocher la nature de leur travail de celui des développeurs informatiques, impliquent déjà des efforts considérables en termes de formation et des modifications substantielles des pratiques. Dans ce contexte, l’adoption des technologies *cloud* dans le cadre de la modernisation du *self* et, par là, l'opportunité pour l'organisation d'en tirer les bénéfices attendus, dépend fortement de notre capacité à les rendre accessibles.

![Onyxia agit comme un "liant" technique entre des composants *cloud native*](/figures/onyxia-components.svg){#fig-onyxia-components}

C'est dans ce contexte que s'inscrit le développement du projet Onyxia, une application légère qui agit essentiellement comme une interface entre les composants modulaires qui composent l’architecture (voir @fig-onyxia-components). Le point d’entrée principal pour l’utilisateur est une application web ergonomique[^onyxia-web] qui permet de lancer des services à partir d’un catalogue de *data science* (voir @sec-catalog)[^images-datascience]. Ces services sont alors immédiatement déployés sous forme de conteneurs sur un *cluster* Kubernetes sous-jacent. Le lien entre l’interface utilisateur (UI) et Kubernetes est assurée par une API [^onyxia-api], dont le rôle est de transformer la demande de lancement de service de l’utilisateur en un ensemble de manifestes nécessaires pour déployer les ressources Kubernetes nécessaires à ce service. Pour une application donnée, ces ressources sont regroupées sous la forme d'un *chart* Helm[^helm-charts-interactive-services], une librairie largement utilisée pour empaqueter des applications potentiellement complexes sur Kubernetes [@gokhale2021creating] et gérer le cycle de vie de ces objets vivants. 

Cette capacité à mettre à disposition des services prêts à l'emploi et ainsi d'abstraire à l'utilisateur la complexité des technologies *cloud* sous-jacentes est véritablement la valeur ajoutée du projet Onyxia. Bien que les utilisateurs puissent configurer un service pour l’adapter à leurs besoins, la plupart du temps, ils se contentent de lancer un service prêt à l’emploi avec des paramètres par défaut et commencent à développer immédiatement. En injectant automatiquement les informations d’authentification et de configuration dans les conteneurs lors de leur initialisation, Onyxia permet aux utilisateurs d'interagir sans difficulté avec les données de leur *bucket* sur MinIO, leurs informations sensibles (jetons, mots de passe) contenues dans un outil de gestion des secrets tel que Vault, etc. Cette injection automatique, associée à la pré-configuration des environnements de *data science* mis à disposition dans le catalogue d’images pour couvrir la plupart des usages courants de *data science*, permet aux utilisateurs d’exécuter des applications potentiellement complexes — comme des calculs distribués avec Spark sur Kubernetes à l’aide de données volumineuses stockées sur MinIO, ou encore l’entraînement de modèles d’apprentissage profond nécessitant un GPU — sans se heurter aux difficultés techniques liées à la configuration des composants nécessaires.

[^onyxia-web]: [https://github.com/InseeFrLab/onyxia]()
[^onyxia-api]: [https://github.com/InseeFrLab/onyxia-api]()
[^images-datascience]: [https://github.com/InseeFrLab/images-datascience]()
[^helm-charts-interactive-services]: [https://github.com/InseeFrLab/helm-charts-interactive-services]()

## Des choix architecturaux visant à favoriser l'autonomie {#sec-principles-autonomy-fr}

Le projet Onyxia repose sur quelques principes structurants, avec un thème central : favoriser l'autonomie, à plusieurs niveaux. Ce principe s'applique d'abord au niveau de l'organisation, en évitant l'enfermement propriétaire. Afin d'obtenir un avantage concurrentiel, une pratique courante que de nombreux fournisseurs de *cloud* commerciaux développent est d'imposer l'utilisation de certaines applications ou protocoles pour accéder aux ressources *cloud*. Souvent, ces dernières ne sont néanmoins pas interopérables : les scripts et pratiques qui fonctionnent avec un fournisseur ne marcheront pas à l'identique avec un autre, compliquant considérablement les migrations potentielles vers une autre plateforme *cloud* [@opara2016critical]. Face à ce constat, une tendance émerge vers l'adoption de stratégies dites "neutres" vis-à-vis des *clouds* afin de réduire la dépendance à des solutions spécifiques d'un seul fournisseur [@opara2017holistic]. Dans cette optique, l'utilisation d'Onyxia est pensée de manière à être intrinsèquement non enfermante : lorsqu'une organisation choisit de l'utiliser, elle choisit les technologies sous-jacentes — la conteneurisation et le stockage d'objets — mais pas la solution en elle-même. Le logiciel Onyxia peut être déployé sur n'importe quel cluster Kubernetes, qu'il soit *on-premise* ou issu d'une offre gérée de *clouds* commerciaux. De même, le choix de MinIO comme solution de stockage contribue à limiter l'enfermement propriétaire. En effet, MinIO est d'une part une solution de stockage objet *open source*, et d'autre part une solution basée sur l'API S3 d'Amazon, qui est progressivement devenu un standard de l'écosystème de la donnée. Ainsi, dans la mesure où les stockages proposés par les divers fournisseurs de *cloud* (AWS, GCP, etc.) s'assurent de leur compatibilité avec cette API, ces choix favorisent une position agnostique qui facilite toute migration ultérieure vers une solution *cloud* différente.

La volonté du projet Onyxia de favoriser l'autonomie s'illustre également au niveau du choix des services. Les logiciels propriétaires qui ont été intensivement utilisé dans les statistiques publiques et la recherche — comme SAS ou STATA — induisent également un phénomène d'enfermement propriétaire. Les coûts des licences, substantiels, peuvent évoluer rapidement et ce dans un contexte de marges de négociation réduites pour l'organisation si son système d'information dépend de manière sensible du code propriétaire. Par ailleurs, si ces logiciels ont l'avantage de mettre à disposition des utilisateurs des procédures statistiques faciles d'utilisation et stables dans la durée, elles contraignent dans le même temps à un ensemble de procédures proposées et maintenues par l'entreprise et limitent donc l'appropriation des nouveaux outils produits par l'écosystème. Par ailleurs, la nature fermée de leur code source empêche d'auditer certaines des procédures en question. A l'inverse, les choix réalisés dans le projet Onyxia visent à minimiser au maximum l'effet d'enfermement des pratiques. D'abord, en n'incluant dans son catalogue que des services *open-source*, Onyxia promeut des logiciels dont il est possible d'auditer le code, ce qui favorise la transparence et la reproductibilité des statistiques produites. Si le catalogue des services offerts est par nature limité, le choix de ces derniers est également transparent : les services proposés doivent être standards, *open source* et s'intégrer avec Kubernetes ; le catalogue est par ailleurs lui-même ouvert à de nouvelles demandes ou des contributions. Enfin, et de manière capitale, Onyxia limite l'enfermement propriétaire en étant conçu de sorte à être amovible. L'objectif final est d'améliorer la familiarité et le confort des utilisateurs avec les technologies *cloud* sous-jacentes et les services standards de *data science*, de sorte à ce qu'ils puissent continuer à utiliser ces services si une autre infrastructure était adoptée. Un exemple illustratif de cette philosophie est l'approche de la plateforme concernant les actions des utilisateurs : pour les tâches effectuées via l'interface , comme le lancement d'un service ou la gestion des données, nous fournissons aux utilisateurs les commandes terminal équivalentes, promouvant ainsi une compréhension fine de ce qui se passe réellement lors de la réalisation d'une action (voir @fig-service-configuration).

![Lancer un service via l'interface web d'Onyxia.](/figures/service-configuration.png){#fig-service-configuration}

Note: Les services du catalogue d'Onyxia peuvent être utilisés tels quels ("*out-of-the-box") ou configurés par les utilisateurs pour répondre à leurs besoins spécifiques. Afin de limiter la dépendance des utilisateurs vis-à-vis d'Onyxia, chaque action effectuée par l'utilisateur via l'interface utilisateur est accompagnée de la commande exacte exécutée sur le cluster Kubernetes sous-jacent.

Si le projet Onyxia a été initialement développé afin de permettre l'expérimentation avec des outils de *data science* à l'état de l'art, les environnements qu'il permet de mettre à disposition se veulent pour autant généralistes. Un objectif majeur du projet est de couvrir une large gamme de besoins exprimés par les statisticiens, de la production statistique courante réalisée en *self* aux usages les plus expérimentaux. Ainsi, cohabitent dans le catalogue de services des environnements de développement usuels — RStudio pour l'usage de R, Jupyter et VSCode pour l'usage de Python — et des environnements pour des usages avancés, mais déployés à travers les mêmes environnements interactifs. Par exemple, lancer des traitements distribués avec Spark en Python se fera également à travers l'usage de Jupyter ou VSCode ; les services de base peuvent ainsi servir de porte d'entrée à des usages plus avancés par la suite. Du fait de la diversité des besoins couverts, les bénéfices à migrer seront différenciés selon les profils. Les utilisateurs dont les besoins actuels sont déjà bien couverts par les infrastructures de *self* existantes bénéficieraient essentiellement de la capacité à spécifier finement les ressources allouées à leur service et ainsi limiter les risques de rentrer en concurrence avec les processus d'autres utilisateurs en cas de saturation de la machine. Les bénéfices à migrer seront en revanche beaucoup plus marqués pour les utilisateurs souhaitant aller plus loin et développer de véritables prototypes d'applications pour leurs projets : configurer des scripts d'initialisation pour adapter les environnements à leurs besoins, déployer une application interactive (par exemple, en R Shiny) pour publier des visualisations de données dynamiques, ou encore déployer des services sur-mesure comme des bases de données à la demande ou bien des prototypes d'API. Pour permettre à ces utilisateurs avancés, souvent limités par la rigidité des environnements de calculs traditionnels, de continuer à faire progresser la structure via des usages innovants, Onyxia offre — selon la politique de sécurité de l'organisation — de larges possibilités de configuration des services et un accès étendu au cluster Kubernetes sous-jacent. Cela signifie que les utilisateurs peuvent ouvrir librement un terminal sur un service interactif et interagir avec le cluster — dans les limites de leur *namespace* — afin d'appliquer des ressources personnalisées et déployer des applications ou d'autres usages de leurs choix.

Au-delà de l'autonomie et de la scalabilité, les choix architecturaux d'Onyxia favorisent également la reproductibilité des calculs statistiques et la portabilité des applications. Dans le paradigme des conteneurs, l'utilisateur doit apprendre à gérer des ressources qui sont par nature éphémères, puisqu'elles n'existent qu'au moment de leur mobilisation effective dans le cadre d'un traitement. Cette non-persistance implique une séparation claire du code — hébergé sur une forge de code, comme GitLab ou GitHub — des données — stockées sur une solution de stockage spécifique, comme MinIO — et de la configuration et des secrets — passés au conteneur sous la forme de variables d'environnement. Au moment du lancement du traitement, le conteneur doit récupérer ces différents éléments (entrées), et produit par construction les mêmes sorties (production de données, modifications dans une base de données, visualisations, etc.) à partir d'un même jeu d'entrées. Cette séparation est un critère fondamental de qualité des projets de code dans la mesure où elle favorise à la fois la reproductibilité et de portabilité. Un conteneur étant nécessairement identifié par un *tag* (label), il est possible dans ce paradigme de versionner non plus seulement le code d'un projet, mais l'ensemble de l'environnement d'exécution qui garantit la reproduction des résultats obtenus à partir des mêmes données en entrée, ce qui constitue un gage de reproductibilité du chiffre statistique. 

Le fait de développer dans des services conteneurisés favorise également la portabilité des projets, c'est à dire leur capacité à s'exécuter de manière homogène quelle que soit l'infrastructure de calcul sous-jacente. Ainsi, et sous réserve d'un accès homogène aux données d'entrée et aux ressources de calcul, un conteneur s'étant exécuté correctement sur une infrastructure de développement en *self* s'exécutera de la même manière sur une infrastructure de production. La conteneurisation permet donc fondamentalement de réduire l'écart existant entre les infrastructures de développement et les infrastructures de production, limitant ainsi les coûts de développement supplémentaires qui caractérisent souvent le passage en production des projets. Cette technologie peut également permettre d'envisager des modes de collaboration plus continus entre les équipes métiers et informatiques. Le fait de s'échanger des conteneurs, c'est à dire des environnements dont on garantit le bon fonctionnement dans l'environnement de développement, plutôt que du code permet aux différentes parties prenantes de se spécialiser sur leur cœur de métier : la spécification, l'écriture de la logique métier, et le débogage éventuel côté équipe métier ; le développement applicatif, les tests fonctionnels, le déploiement et la supervision côté informatique — limitant par là le besoin coûteux mais fréquent de fait de recoder des applications d'un langage statistique vers un langage informatique.

## Un catalogue de services qui couvre le cycle de vie complet des projets de *data science* {#sec-catalog}

L'intention du projet Onyxia est de fournir aux statisticiens un environnement complet conçu pour accompagner le développement de bout en bout des projets de *data science*. Comme illustré dans @fig-onyxia-catalog, le catalogue par défaut propose une vaste gamme de services couvrant l'ensemble du cycle de vie d'un projet, du développement à la diffusion.

![Le catalogue d'Onyxia vise à couvrir l'ensemble du cycle de vie des projets de data science](/figures/onyxia-catalog.svg){#fig-onyxia-catalog}

L'utilisation principale de la plateforme est le déploiement d'environnements de développement interactifs (IDE), tels que RStudio, Jupyter ou VSCode. Ces IDE sont voulus comme étant "prêts à l'emploi" : ils sont équipés des dernières versions des principaux langages de programmation *open source* couramment utilisés par les statisticiens publics (R, Python, SQL, Julia) ainsi que des librairies les plus fréquemment utilisées pour chaque langage. Afin de garantir que les services restent à jour et cohérents entre eux, l'Insee maintient un dépôt d'images Docker sous-jacentes et les met à jour chaque semaine. Ces images sont entièrement *open source*[^images-datascience] et peuvent donc être réutilisée en dehors du projet.

Comme décrit dans les sections précédentes, la couche de persistance de ces environnements interactifs est principalement assurée par MinIO, une solution de stockage objet *open source*. Cette solution étant basée sur une API REST standardisée, les fichiers peuvent être facilement interrogés depuis R ou Python à l'aide de librairies de haut niveau. Cela représente en soi une étape importante pour garantir la reproductibilité : les données ne sont pas sauvegardées localement, puis appelées via des chemins propres à une infrastructure ou un système de fichiers particulier. Au contraire, les requêtes aux fichiers sont spécifiées sous forme de requêtes HTTP standards, rendant la structure globale des projets plus évolutive. Les traitements rencontrés dans le service statistique public reposant très largement sur des fichiers de données, le paradigme du stockage objet répond très bien aux besoins de la plupart des projets que nous accompagnons sur ces infrastructures. Des services de bases de données supplémentaires, tels que PostgreSQL et MongoDB, sont également proposés pour les applications ayant des besoins spécifiques, notamment celles nécessitant de traitement géospatial en base (PostGIS) ou un stockage de données orienté documents.

Onyxia ayant été développé afin de permettre l'expérimentation avec des sources de données volumineuses, le catalogue propose également des services facilitant le passage à l'échelle. Pour les projets faisant intervenir des données volumineuses — de l'ordre de dizaines ou de centaines de millions de ligne — les différents services disposent nativement des librairies Arrow et DuckDB, permettant de traiter efficacement les données stockées au format Parquet en mémoire. Pour des usages plus conséquents, faisant intervenir des données massives, des logiciels comme Spark et Trino permettent d'effectuer des calculs distribués au sein d'un cluster Kubernetes via un simple lancement de service interactif ou d'un *batch* de traitement. Dans les deux cas, ces services sont préconfigurés pour s'intégrer naturellement avec le stockage S3, facilitant ainsi la création de *pipelines* de données à la fois efficients et intégrés de bout en bout. Enfin, différents services pré-configurés pour l'utilisation d'une GPU sont également proposés pour les projets basés sur des méthodes d'apprentissage automatique intensives en calcul. Le catalogue d'Onyxia fournit donc un point d'entrée unique pour mettre à disposition ces ressources rares ainsi que des librairies spécialisées — par exemple, les librairies de *deep learning* PyTorch et Tensorflow — avec la même simplicité que le lancement d'un service interactif de base.

Au-delà de la phase expérimentation, l'objectif est également de permettre aux statisticiens de produire des projets dits de "quasi-prod", au sens où ils préfigurent un passage en production afin d'en faciliter sa réalisation. Conformément aux principes de l'approche *DevOps*, cela implique de faciliter le déploiement de prototypes et leur amélioration continue au fil du temps. À cette fin, le catalogue d'Onyxia propose un ensemble de services *open source* visant à automatiser et industrialiser le processus de déploiement d'applications (ArgoCD), ordonnancer des traitements séquentiels et/ou parallèles (Argo-Workflows), ou encore déployer et gérer le cycle de vie des modèles d'apprentissage automatique (MLflow). La [Section 4](/src/mlops/index.qmd#sec-mlops) illustre comment ces outils ont joué un rôle central dans la mise en production de premiers modèles d'apprentissage automatique à l’Insee, conformément aux principes du MLOps.

Dans la @sec-principles-autonomy-fr, nous avons souligné qu'un des principes fondamentaux d'Onyxia était d'éviter l'enfermement propriétaire. Dans cette optique, les organisations qui instancient Onyxia sont libres de personnaliser les catalogues pour répondre à leurs besoins spécifiques, ou même de créer leurs propres catalogues indépendamment de l'offre par défaut. Cette flexibilité garantit aux organisations le fait de ne pas être limité à une solution ou à un fournisseur unique, et ainsi de pouvoir adapter la plateforme à l'évolution de leurs besoins ou de migrer vers une autre solution *cloud* dans le futur si nécessaire.

## Construire des communs numérique : un projet, plusieurs instances {#sec-instances}

En tant qu'initiative entièrement *open source*, le projet Onyxia vise à construire des "communs numériques" en promouvant et en développant des logiciels facilement réutilisables dans le service statistique publique et plus largement [@schweik2006free]. Cela concerne, tout d'abord, les composants sur lesquels repose Onyxia : à la fois ses briques technologiques (Kubernetes, MinIO, Vault) de même que l'ensemble des services du catalogue sont *open source*. De même, le code source du projet Onyxia est disponible publiquement sur GitHub[^onyxia-github] sous licence MIT ce qui, associé à une documentation détaillée[^onyxia-docs], favorise les réutilisations du projet. Enfin, cette orientation est sensible à travers les principes architecturaux qui ont guidé le développement du projet. La notion de "région", qui permet de paramétriser finement la configuration du logiciel et son interaction avec le cluster Kubernetes sous-jacent, la possibilité de définir simplement des identités graphiques spécifiques (voir @fig-onyxia-instances), et la possibilité d'adapter la catalogue de services (cf. supra) facilitent les ré-instanciations et l'appropriation du projet par les organisations.

![Un projet, de multiples instances : l'interface web est adaptable à l'identité graphique de chaque organisation](/figures/onyxia-instances.png){#fig-onyxia-instances}

En 2025, deux instances d'Onyxia cohabitent à l'Insee, couvrant chacune des besoins différents. L'instance historique, nommée SSP Cloud, est l'instance "vitrine" du projet Onyxia. Équipée de ressources de calcul conséquentes[^cluster] et du catalogue de services le plus complet, cette plateforme est conçue comme un bac à sable permettant d'expérimenter en toute autonomie des nouvelles méthodes et outils de *data science* [@comte2022sspcloud]. Au-delà de ses capacités techniques, le SSP Cloud incarne les principes de l'innovation ouverte [@chesbrough2003open]. Déployée sur internet[^datalab], la plateforme est accessible non seulement aux agents de l'Insee mais également, plus largement, aux agents des ministères et des collectivités, aux universités et grandes écoles françaises, et aux autres INS européens. La nature fondamentalement collaborative du SSP Cloud s'est avérée particulièrement adaptée à l'organisation d'événements innovants, tels que des *hackathons*, tant au niveau national qu'international. Il est devenu une ressource intégrale pour plusieurs universités et grandes écoles françaises, favorisant l'enseignement des technologies *cloud* tout en évitant l'effet d'enfermement propriétaire dû à une dépendance excessive des institutions éducatives envers des solutions *cloud* propriétaires. En conséquence, la plateforme est désormais largement utilisée dans le service statistique publique français et plus largement, avec environ 1000 utilisateurs uniques par mois. Ces utilisateurs forment une communauté dynamique grâce à un canal de discussion centralisé[^tchap_sspcloud] ; ils contribuent à améliorer l'expérience utilisateur en signalant des *bugs*, en proposant de nouvelles fonctionnalités et en contribuant ainsi directement au projet.

Si le côté résolument ouvert du SSP Cloud rend cette instance particulièrement adaptée à la préfiguration de nouveaux usages, il impose en contrepartie l'utilisation de données ouvertes dans les projets qui y sont menés. A ce titre, cette instance ne pouvait servir de plateforme de traitements de données confidentielles à l'Insee. Pour pallier cette limite, les équipes de la DSI ont mis en place en 2025 une plateforme de calcul à la fois moderne — basée sur les technologies *cloud* présentées dans cet article : conteneurisation et stockage objet — et homologuée pour le traitement des données confidentielles. Nommée "LS³" — pour libre service "kube", en référence au cluster Kubernetes sous-jacent — cette plateforme se positionne en complémentarité à AUSv3, avec pour ambition d'offrir un cadre de travail plus moderne pour les cas d'usage déjà correctement couverts et de répondre aux besoins fonctionnels aujourd'hui non ou mal couverts par cette dernière (déploiement d'applications interactive et de bases de données, calcul distribué, ordonnancement de traitements, etc.). Basée sur le logiciel Onyxia, la plateforme LS³ hérite des développements continus qui améliorent le projet, que ce soit sur l'interface utilisateur — par exemple, le développement d'un explorateur de données permettant de visualiser rapidement le contenu d'un fichier Parquet — où dans le catalogue de services, dont LS³ reprend les services les plus utilisés. A contrario, les retours des utilisateurs de plus en plus nombreux de cette plateforme permettent d'améliorer les composants d'Onyxia, bénéficiant à l'ensemble des instances déployées du projet.

La possibilité pour d'autres organisations de déployer leur propre instance interne d'Onyxia et de l'adapter à leurs besoins spécifiques (voir @fig-onyxia-instances) a permis le développement du projet au delà de l'Insee. Des instances d'Onyxia sont désormais en production dans des organisations de différente nature : INS (Statistique Norvège), organisations internationales (ONU), ONG (Mercator Ocean[^mercator]), et plusieurs autres sont en phase d'expérimentation. Cette diffusion a permis d'attirer une communauté croissante de contributeurs au projet *open-source*, favorisant une transition progressive vers une gouvernance plus décentralisée du projet. Dans les prochaines années, l'implication des INS européens devrait se renforcer, le SSPCloud ayant été choisi comme plateforme  de référence dans le cadre du projet AIML4OS[^aiml4os].


[^mercator]: Lien vers l'instance Onyxia de Mercator Ocean : [https://datalab.dive.edito.eu/]()
[^onyxia-github]: [https://github.com/InseeFrLab/onyxia]()
[^onyxia-docs]: [https://docs.onyxia.sh/]()
[^aiml4os]: Plus d'informations à propos de ce projet sont disponibles sur cette page : [https://cros.ec.europa.eu/dashboard/aiml4os]()
[^cluster]: Sur le plan matériel, le SSP Cloud est constitué d'un cluster Kubernetes d'environ 20 serveurs, pour une capacité totale de 10 To de RAM, 1100 processeurs, 34 GPU et 150 To de stockage.
[^datalab]: [https://datalab.sspcloud.fr/]()
[^tchap_sspcloud]: Lien vers les canaux de discussion : [https://www.tchap.gouv.fr/#/room/#SSPCloudXDpAw6v:agent.finances.tchap.gouv.fr](Canal Tchap du SSP Cloud) et [https://join.slack.com/t/3innovation/shared_invite/zt-19tht9hvr-bZGMdW8AV_wvd5kz3wRSMw](Canal Slack du projet Onyxia)
