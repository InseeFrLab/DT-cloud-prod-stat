---
number-offset: 2
---

::: {.content-visible when-profile="en"}

# Onyxia: an open source project to build cloud-native data science platforms {#sec-implementation}

This section explores how Onyxia, an open-source project initiated at Insee, democratizes access to cloud technologies for statisticians by providing modern data science environments that foster autonomy. We discuss how this initiative fits in with the general aim of creating "knowledge commons" by promoting and building software that can be easily reused in the field of official statistics and beyond.

## Making cloud-technologies accessible to statisticians

Our technology watch and literature review highlighted cloud-native technologies, in particular containerization and object storage, as instrumental in building a data science platform that is both scalable and flexible. Building on these insights, we established our initial on-premise Kubernetes cluster in 2020, integrating it with MinIO, an open-source object storage system designed to work seamlessly with Kubernetes. Yet, our first experiments highlighted a significant barrier to the widespread adoption of cloud-native technologies: the complexity of their integration. This is an important consideration when building data architectures that prioritize modularity — an essential feature for the flexibility we aim to achieve[^flexibility]. However, modularity of the architecture components also entails that any data application launched on the cluster must be configured so as to communicate with all the components. For instance, in a big data setup, configuring Spark to operate on Kubernetes while interacting with datasets stored in MinIO requires an intricate set of configurations (specifying endpoints, access tokens, etc.), a skill set that typically lies beyond the expertise of statisticians.

[^flexibility]: A telling example of the importance of building a modular architecture is the ability to switch between storage sources (on-premise, public cloud provider, etc.). The storage solution we chose, MinIO, is compatible with Amazon's S3 API, which has become a de facto standard in the cloud ecosystem due to the success of Amazon's AWS S3 storage solution. As a result, organizations that choose to use Onyxia are not tied to a specific storage solution: they can choose any solution that complies with the standards defined by the S3 API.


For instance, due to MinIO's compatibility with the Amazon S3 API, the storage source could easily be switched to one managed by another public cloud provider, without requiring substantial modifications.

This insight is really the base of the Onyxia project: choosing technologies that foster autonomy will not actually foster autonomy if their complexity acts as a barrier from widespread adoption in the organization. In recent years, statisticians at Insee already needed to adapt to a changing environment in terms of their everyday tools: transitioning from proprietary software (SAS®) to open-source ones (R, Python), acculturating to technologies that improve reproducibility (version control with Git), consuming and developing APIs, etc. These changes, making their job more and more akin to the one of software developers, already imply significant training and changes in daily work practices. Against this background, adoption of cloud-technologies was utterly dependent on making them readily accessible.

![Onyxia is the technical binder between cloud-native modular components](../../figures/onyxia-components.png){#fig-onyxia-components}


To bridge this gap, we developed Onyxia, an application that essentially acts as interface between the modular components that compose the architecture (see @fig-onyxia-components). The main entry point of the user is a user-friendly web application[^onyxia-ui]  that enables users to launch services from a data science catalog (see @sec-catalog) as running containers on the underlying Kubernetes cluster. The interface between the UI and Kubernetes is done by a lightweight custom API[^onyxia-api], that essentially transforms the application request of the user into a set of manifests to deploy Kubernetes resources. For a given application, these resources are packaged under the form of Helm charts, a popular way of packaging potentially complex applications on Kubernetes [@gokhale2021creating]. Although users can configure a service to tailor it to their needs, they will most of the time just launch an out-of-the-box service with default settings and start developing straight away. This point really illustrates the added value of Onyxia in facilitating the adoption of cloud technologies. By injecting authentication information and configuration into the containers at the initialization, we ensure that users can launch and manage data science services in which they can interact seamlessly with the data from their bucket on MinIO, their sensitive information (tokens, passwords) in a secret management tool such as Vault, etc. This automatic injection, coupled with the pre-configuration of data science environments in Onyxia's catalogs of images[^images-datascience] and associated helm-charts[^helm-charts-interactive-services], make it possible for users to execute potentially complex workloads — such as running distributed computations with Spark on Kubernetes using data stored in S3, or training deep-learning models using a GPU — without getting bogged down by the technicalities of configuration.

[^onyxia-ui]: [https://github.com/InseeFrLab/onyxia-ui]()
[^onyxia-api]: [https://github.com/InseeFrLab/onyxia-api]()
[^images-datascience]: [https://github.com/InseeFrLab/images-datascience]()
[^helm-charts-interactive-services]: [https://github.com/InseeFrLab/helm-charts-interactive-services]()

## Architectural choices aimed at fostering autonomy {#sec-principles-autonomy}

The Onyxia project is based on a few structuring principles, with a central theme: fostering autonomy, both at the organizational and individual levels. First, at the level of the organization by preventing vendor lock-in. In order to get a competitive edge, many commercial cloud providers develop applications and protocols that customers need to use to access cloud resources, but that are not interoperable, greatly complexifying potential migrations to another cloud platform [@opara2016critical]. Recognizing these challenges, there is a trend towards endorsing cloud-neutral strategies [@opara2017holistic] in order to reduce reliance on a single vendor’s specific solutions. In contrast, the use of Onyxia is inherently not restrictive: when an organization chooses to use it, it chooses the underlying technologies — containerization and object storage — but not the solution. The platform can be deployed on any Kubernetes cluster, either on-premise or in public clouds. Similarly, Onyxia was designed to be used with MinIO because it is an open-source object-storage solution, but is also compatible with objects storage solutions from various cloud providers (AWS, GCP).

Onyxia also fosters autonomy at the level of users. Proprietary softwares that have been used intensively in official statistics — such as SAS or STATA — also produce a vendor lock-in phenomenon. The costs of licensing are high and can evolve quickly, and users are tied in certain ways of performing computations, preventing progressive upskilling. On the contrary, Onyxia aspires to be removable; we want to enhance users' familiarity and comfort with the underlying cloud technologies rather than act as a permanent fixture in their workflow. An illustrative example of this philosophy is the platform's approach to user actions: for tasks performed through the UI, such as launching a service or managing data, we provide users with the equivalent terminal commands, promoting a deeper understanding of what actually happens on the infrastructure when triggering something. Furthermore, all the services offered through Onyxia's catalog are open-source.

![Launching a service through Onyxia's UI.](../../figures/service-configuration.png){#fig-service-configuration}

Note: Services from Onyxia's catalog can either be used vanilla or configured by the users to tailor them to their specific needs. In order to limit the dependence of users on Onyxia, each action performed by the user on the UI is accompanied by the actual command that is executed on the Kubernetes cluster.


Naturally, the way Onyxia makes statisticians more autonomous in their work depends on their needs and familiarity with IT skills. Statisticians that just want to have access to extensive computational resources to experiment with new data sources or statistical methods will have access in a few clicks to easy-to-use, pre-configured data science environments, so that they can directly start to experiment. However, many users want to go deeper and build actual prototypes of production applications for their projects: configuring initialization scripts to tailor the environments to their needs, deploying an interactive app that delivers data visualization to users of their choice, deploying other services than those available in our catalogs, etc. For these advanced users to continue to push the boundaries of innovation, Onyxia gives them access to the underlying Kubernetes cluster. This means that users can freely open a terminal on an interactive service and interacts with the cluster - within the boundaries of their namespace - in order to apply custom resources and deploy custom applications or services.

Besides autonomy and scalability, the architectural choices of Onyxia also foster reproducibility of statistical computations. In the paradigm of containers, the user must learn to deal with resources which are by nature ephemeral, since they only exist at the time of their actual mobilization. This fosters the adoption of development best practices, notably the separation of the code — put on an internal or open-source forge such as GitLab or GitHub — the data — stored on a specific storage solution, such as MinIO — and the computing environment. While this requires an entry cost for users, it also helps them to conceive their projects as pipelines, i.e. a series of sequential steps with well-defined inputs and outputs (akin to directed acyclic graph (DAG)). The projects developed in that manner are usually more reproducible and portable — they can work seamlessly on different computing environments — and thus also more readily shareable with peers.

## An extensive catalogue of services to cover the entire lifecycle of data science projects {#sec-catalog}

In developing the Onyxia platform, our intention was to provide statisticians with a comprehensive environment designed to support end-to-end development of data science projects. As depicted in @fig-onyxia-catalog, the platform offers a vast array of services that span the complete lifecycle of a data science project.

![Onyxia's catalog aims at covering the entire lifecycle of data science projects](../../figures/onyxia-catalog.png){#fig-onyxia-catalog}

The primary usage of the platform is the deployment of interactive development environments (IDE), such as RStudio, Jupyter, or VSCode. These IDEs come equipped with the latest kernels of major open-source programming languages commonly employed by public statisticians (R, Python, Julia), as well as an extensive collection of packages commonly used in data science for each language. In order to ensure that services remain up-to-date and consistent between them, we maintain our own stack of underlying Docker images and rebuild it weekly. The stack of images is fully open-source[^images-datascience] and can thus be reused outside Onyxia.


As discussed in previous sections, the persistence layer of these interactive environments is mainly carried out by MinIO, Onyxia's default object storage solution. As it is based on a standardized REST API, files can be easily queried directly from R or Python using high-level packages. This in itself is an important step of ensuring reproducibility: the input files of a project are not mounted manually and then specified via paths adherent to a specific infrastructure and filesystem. Rather, files are specified as HTTP queries, making the overall structure of projects much more extendable. In our experience, the object-storage paradigm covers very well the needs of most statistical projects we accompany. However, additional database services such as PostgreSQL and MongoDB are available for applications with specific needs, such as those requiring online transaction processing (OLTP) capabilities or document-oriented storage.

As Onyxia was developed to allow experimentation with big data sources and machine learning methods, we also provide services optimized for scalability. For instance, frameworks like Spark and Trino that enable to perform distributed computations within Kubernetes. These services come pre-configured to integrate seamlessly with S3 storage, thus facilitating building integrated and efficient data pipelines.

Beyond mere experimentation, our goal is to empower statisticians to transition from trial phases to production-grade projects. In lines with principles from the DevOps approach, this involves facilitating the deployment of prototypes and their continuous improvement over time. To this end, we provide a set of open-source tools aimed at automatizing and industrializing the process of deploying data-intensive applications (ArgoCD, Argo-Workflows, MLflow). For projects leveraging machine-learning models, statisticians can serve their models through APIs, deploy them using the aforementioned tools, and manage their lifecycle using an API manager (e.g. Gravitee). [Section 4](../mlops/index.qmd#sec-mlops) will illustrate how these tools, particularly MLflow, have been central in putting machine learning models in production at Insee, in accordance with MLOps principles.

In @sec-principles-autonomy, we stressed that one of Onyxia's fundamental design principle was to avoid vendor lock-in. In line with this idea, organizations that implement Onyxia are free to customize catalogs to suit their specific requirements, or even opt to construct their own catalogs independent of Onyxia's default offerings. This flexibility ensures that organizations are not confined to a single solution or provider, and can adapt the platform to their evolving needs.

## Building commons: an open-source project and an open-innovation platform

As a fully open-source initiative, the Onyxia project aims at building "knowledge commons" by promoting and building software that can be easily reused in official statistics and beyond [@schweik2006free]. This concerns, first of all, the components on which Onyxia are based: both its constitutive technological bricks (Kubernetes, MinIO, Vault) as well as all the services from the catalog are open-source. But more crucially, all the code of the project is available openly on GitHub[^onyxia-github]. Alongside an in-depth documentation[^onyxia-docs], this greatly facilitates the potential for other organizations to create instances of data science platforms built upon the Onyxia software and tailor it to their respective needs (see @fig-onyxia-instances). This enabled the project to attract a growing community of contributors from official statistics (Statistics Norway), NGOs (Mercator Ocean), research centres and even industry, thus transitioning progressively towards a more decentralized governance of the project. In the next years, the involvement of NSIs from the European Statistical System is expected to increase as Onyxia was chosen as the reference data science platform in the context of the AIML4OS project, a "One-Stop-Shop" for Artificial Intelligence/Machine Learning for Official Statistics in the European Statistical System[^aiml4os].

[^onyxia-github]: [https://github.com/InseeFrLab/onyxia]()
[^onyxia-docs]: [https://docs.onyxia.sh/]()
[^aiml4os]: More information on this project available at [https://cros.ec.europa.eu/dashboard/aiml4os]()

![One project, multiple instances: the UI is adaptable to the graphic identity of the organization](../../figures/onyxia-instances.png){#fig-onyxia-instances}

Another major way in which we try to build commons is by developing and maintaining a showcase instance of the Onyxia project, the SSP Cloud [@comte2022sspcloud]. This platform, equipped with extensive and scalable computational resources[^cluster], is designed to be a sandbox for experimenting with cloud technologies and new data science methods. The full catalog of services of Onyxia is available on the platform, enabling motivated users to go beyond mere experimentation by producing "proof of concepts", with full autonomy regarding the configuration and orchestration of their services.

[^cluster]: On the physical side, the SSP Cloud consists in a Kubernetes cluster of about 20 servers, for a total capacity of 10 TB of RAM, 1100 CPUs, 34 GPUs and 150 TB of storage.

Beyond its technical capabilities, the SSP Cloud is an endeavour at embodying the principles of open-innovation [@chesbrough2003open]. Deployed on internet[^datalab], it is open not only to Insee employees, but also more broadly to French governmental agencies, French Universities and other European NSIs, and is dedicated to experimenting with data science methods using open data. Thus, the projects carried out on this platform showcase the growing abundance of datasets published openly by organizations. The fundamentally collaborative nature of the SSP Cloud has proven especially beneficial for organizing innovative events such as hackathons — both at the national and international levels — and in the academic sphere. It has become an integral resource for several universities and Grandes Ecoles in France, fostering the use of cloud-native and reproducible environments, and preventing vendor lock-in effect due to the over-reliance of educational organizations on proprietary cloud solutions. As a result, the platform is now widely used in the French National Statistical System and beyond, with about 800 unique users per month in 2024. These users form a dynamic community thanks to a centralized discussion canal; they help improve the user experience by reporting bugs, suggesting new features, and thus contribute directly to the project.

[^datalab]: [https://datalab.sspcloud.fr/]()


:::


<!-- ############################################################################################################## -->
<!-- ############################################################################################################## -->
<!-- ############################################################################################################## -->



::: {.content-visible when-profile="fr"}

# Un projet *open source* pour faciliter l'adoption des technologies *cloud* {#sec-implementation-fr}

Notre revue de la littérature et de l'évolution de l'éco-système de la donnée mettent en évidence les technologies *cloud*, en particulier la conteneurisation et le stockage objet, comme des éléments clés pour construire une plateforme de *data science* à la fois scalable et flexible. Néanmoins, les arguments qui justifient d'investir dans ce type d'infrastructure en tant qu'organisation ne suffisent pas à eux seuls à garantir leur adoption dans les pratiques. Cette section revient sur la genèse et le développement d'Onyxia, un projet développé à l’Insee qui vise à démocratiser l’accès aux technologies *cloud* en fournissant aux statisticiens des environnements de *data science* prêts à l'emploi qui favorisent l'expérimentation. Enfin, nous montrons comment les principes fondamentaux qui sous-tendent le projet Onyxia — innovation ouverte, licence *open-source* absence d'enfermement propriétaire — s’inscrit dans une volonté de construire des communs numériques ("*commons*") facilement réutilisables par les organisations. Ces principes ont permis le développement du projet à la fois à l'Insee et en dehors de l'Insee avec plusieurs instances en production et de nombreuses autres à l'essai.

## Rendre les technologies *cloud* accessibles aux statisticiens

En 2017, un hackathon NTTS est organisé par Eurostat sur le problème d'adéquation entre l’offre et la demande de compétences sur le marché du travail à un niveau régional. Une équipe regroupant des agents de la DMCSI et de la DSI se constitue pour appréhender ces données volumineuses d'un type nouveau, anticipant l'insuffisance de la plateforme AUSv1, alors infrastructure de référence pour les traitements réalisés en *self* à l'Insee. Cette composition mixte de l'équipe participante permet de mettre en lumière un certain paradoxe dans la mise à disposition des ressources de calcul à l'Insee. Là où les *data scientists* de l'équipe ne demandent qu'à avoir accès à un environnement de calcul leur fournissant à la fois un minimum de ressources de calcul et leur permettant d'installer de nouveaux outils librement pour pouvoir mettre en place leurs idées, les informaticiens disposent quant à eux de l'ensemble de la puissance du *data center* mais n'en utilisent qu'une fraction dans le cadre de traitements de sécurité. Au-delà de la belle réussite finale — l'équipe Insee obtient la deuxième place — ce hackathon illustre l'intrication croissante des sujets méthodologiques et informatiques dans le paradigme de la *data science*, et amène la DSI à s'interroger quant à la manière de redonner de l'autonomie aux statisticiens dont le métier évolue vers des pratiques plus coûteuses en ressources. Ce petit groupe de pirates [@comte2022sspcloud] s'est alors saisi d'une double opportunité : une nouvelle technologie de rupture — les technologies *cloud* — parfaitement adaptée au enjeux de la *data science* et des serveurs décommissionnés à la Direction Générale. Cette initiative aboutit à la mise en place d'un premier cluster Kubernetes dans les locaux de l'Insee en 2020.

Cependant, les premières expérimentations révèlent un obstacle majeur à l’adoption généralisée des technologies *cloud* : la complexité de leur intégration. Les infrastructures *cloud* sont par nature modulaires, faites de différents composants faiblement couplés. C'est précisément cette modularité qui favorise le passage à l'échelle et l'évolutivité de ces architectures. Cette modularité a néanmoins une contrepartie importante : la nécessité de configurer finement ces différents composants pour leur permettre de communiquer entre eux. Ainsi, un simple service RStudio lancé sur le *cluster* ne suffit pas en soi : il doit pouvoir communiquer avec la couche de stockage des données, le service de gestion des secrets, d'autres services éventuels permettant par exemple l'ordonnancement des traitements, etc. Ces configurations sont complexes et nombreuses et ne sauraient être demandées aux statisticiens désireux de bénéficier des avantages des infrastructures *cloud* dans le cadre de leurs traitements.

Ce constat est capital : choisir des technologies qui favorisent l’autonomie ne suffit pas à atteindre cet objectif si leur complexité constitue une barrière trop importante à leur adoption dans l’organisation. Ces dernières années, les statisticiens de l’Insee ont déjà dû s’adapter à un environnement en forte évolution en ce qui concerne leurs outils quotidiens : passer de logiciels propriétaires (SAS) à des outils open source (R, Python), s’approprier des technologies qui améliorent la reproductibilité (contrôle de version avec Git), consommer voire développer des API, etc. Ces changements, qui tendent à rapprocher la nature de leur travail de celui des développeurs informatiques, impliquent déjà des efforts considérables en termes de formation et des modifications substantielles des pratiques. Dans ce contexte, l’adoption des technologies *cloud* dans le cadre de la modernisation du *self* et, par là, l'opportunité pour l'organisation d'en tirer les bénéfices attendus, dépend fortement de notre capacité à les rendre accessibles.

![Onyxia agit comme un "liant" technique entre des composants *cloud native*](../../figures/onyxia-components.svg){#fig-onyxia-components}

C'est dans ce contexte que s'inscrit le développement du projet Onyxia, une application légère qui agit essentiellement comme une interface entre les composants modulaires qui composent l’architecture (voir @fig-onyxia-components). Le point d’entrée principal pour l’utilisateur est une application web ergonomique[^onyxia-web] qui permet de lancer des services à partir d’un catalogue de *data science* (voir @sec-catalog)[^images-datascience]. Ces services sont alors immédiatement déployés sous forme de conteneurs sur un *cluster* Kubernetes sous-jacent. Le lien entre l’interface utilisateur (UI) et Kubernetes est assurée par une API [^onyxia-api], dont le rôle est de transformer la demande de lancement de service de l’utilisateur en un ensemble de manifestes nécessaires pour déployer les ressources Kubernetes nécessaires à ce service. Pour une application donnée, ces ressources sont regroupées sous la forme d'un *chart* Helm[^helm-charts-interactive-services], une librairie largement utilisée pour empaqueter des applications potentiellement complexes sur Kubernetes [@gokhale2021creating] et gérer le cycle de vie de ces objets vivants. 

Cette capacité à mettre à disposition des services prêts à l'emploi et ainsi d'abstraire à l'utilisateur la complexité des technologies *cloud* sous-jacentes est véritablement la valeur ajoutée du projet Onyxia. Bien que les utilisateurs puissent configurer un service pour l’adapter à leurs besoins, la plupart du temps, ils se contentent de lancer un service prêt à l’emploi avec des paramètres par défaut et commencent à développer immédiatement. En injectant automatiquement les informations d’authentification et de configuration dans les conteneurs lors de leur initialisation, Onyxia permet aux utilisateurs d'interagir sans difficulté avec les données de leur *bucket* sur MinIO, leurs informations sensibles (jetons, mots de passe) contenues dans un outil de gestion des secrets tel que Vault, etc. Cette injection automatique, associée à la pré-configuration des environnements de *data science* mis à disposition dans le catalogue d’images pour couvrir la plupart des usages courants de *data science*, permet aux utilisateurs d’exécuter des applications potentiellement complexes — comme des calculs distribués avec Spark sur Kubernetes à l’aide de données volumineuses stockées sur MinIO, ou encore l’entraînement de modèles d’apprentissage profond nécessitant un GPU — sans se heurter aux difficultés techniques liées à la configuration des composants nécessaires.

[^onyxia-web]: [https://github.com/InseeFrLab/onyxia]()
[^onyxia-api]: [https://github.com/InseeFrLab/onyxia-api]()
[^images-datascience]: [https://github.com/InseeFrLab/images-datascience]()
[^helm-charts-interactive-services]: [https://github.com/InseeFrLab/helm-charts-interactive-services]()

## Des choix architecturaux visant à favoriser l'autonomie {#sec-principles-autonomy-fr}

Le projet Onyxia repose sur quelques principes structurants, avec un thème central : favoriser l'autonomie, à plusieurs niveaux. Ce principe s'applique d'abord niveau de l'organisation, en évitant l'enfermement propriétaire. Afin d'obtenir un avantage concurrentiel, une pratique courante de nombreux fournisseurs de *cloud* commerciaux développent est d'imposer l'utilisation de certaines applications ou protocoles pour accéder aux ressources *cloud*. Souvent, ces dernières ne sont néanmoins pas interopérables : les scripts et pratiques qui fonctionnent avec un fournisseur ne marcheront pas à l'identique avec un autre, compliquant considérablement les migrations potentielles vers une autre plateforme *cloud* [@opara2016critical]. Face à ce constat, une tendance émerge vers l'adoption de stratégies dites "neutres" vis-à-vis des *clouds* afin de réduire la dépendance à des solutions spécifiques d'un seul fournisseur [@opara2017holistic]. Dans cette optique, l'utilisation d'Onyxia est pensée de manière à être intrinsèquement non-enfermante : lorsqu'une organisation choisit de l'utiliser, elle choisit les technologies sous-jacentes — la conteneurisation et le stockage d'objets — mais pas la solution en elle-même. Le logiciel Onyxia peut être déployé sur n'importe quel cluster Kubernetes, qu'il soit *on-premise* ou issu d'une offre gérée de *clouds* commerciaux. De même, le choix de MinIO comme solution de stockage contribue à limiter l'enfermement propriétaire. En effet, MinIO est une d'une part une solution de stockage objet *open source*, et d'autre part une solution basée sur l'API S3 d'Amazon, qui est progressivement devenu un standard de l'éco-système de la donnée. Ainsi, dans la mesure où les stockages proposés par les divers fournisseurs de *cloud* (AWS, GCP, etc.) s'assurent de leur compatibilité avec cette API, ces choix favorisent une position agnostique qui facilite toute migration ultérieure vers une solution *cloud* différente.

La volonté du projet Onyxia de favoriser l'autonomie s'illustre également au niveau du choix des services. Les logiciels propriétaires qui ont été intensivement utilisé dans les statistiques publiques et la recherche — comme SAS ou STATA — induisent également un phénomène d'enfermement propriétaire. Les coûts des licences, substantiels, peuvent évoluer rapidement et ce dans un contexte de marges de négociation réduites pour l'organisation si son système d'information dépend de manière sensible du code propriétaire. Par ailleurs, si ces logiciels ont l'avantage de mettre à disposition des utilisateurs des procédures statistiques faciles d'utilisation et stables dans la durée, elles contraignent dans le même temps à un ensemble de procédures proposées et maintenues par l'entreprise et limitent donc l'appropriation des nouveaux outils produits par l'éco-système. Par ailleurs, la nature fermée de leur code source empêche d'auditer certaines des procédures en question. A l'inverse, les choix réalisés dans le projet Onyxia visent à minimiser au maximum l'effet d'enfermement des pratiques. D'abord, en n'incluant dans son catalogue que des services *open-source*, Onyxia promeut des logiciels dont il est possible d'auditer le code, ce qui favorise la transparence et la reproductibilité des statistiques produites. Si le catalogue des services offerts est par nature limité, le choix de ces derniers est également transparent : les services proposés doivent être standards, *open source* et s'intégrer avec Kubernetes ; le catalogue est par ailleurs lui-même ouvert à de nouvelles demandes ou des contributions. Enfin, et de manière capitale, Onyxia limite l'enfermement propriétaire en étant conçu de sorte à être amovible. L'objectif final est d'améliorer la familiarité et le confort des utilisateurs avec les technologies *cloud* sous-jacentes et les services standards de *data science*, de sorte à ce qu'ils puissent continuer à utiliser ces services si une autre infrastructure était adoptée. Un exemple illustratif de cette philosophie est l'approche de la plateforme concernant les actions des utilisateurs : pour les tâches effectuées via l'interface , comme le lancement d'un service ou la gestion des données, nous fournissons aux utilisateurs les commandes terminal équivalentes, promouvant ainsi une compréhension fine de ce qui se passe réellement lors de la réalisation d'une action (voir @fig-service-configuration).

![Lancer un service via l'interface web d'Onyxia.](../../figures/service-configuration.png){#fig-service-configuration}

Note: Les services du catalogue d'Onyxia peuvent être utilisés tels quels ("*out-of-the-box") ou configurés par les utilisateurs pour répondre à leurs besoins spécifiques. Afin de limiter la dépendance des utilisateurs vis-à-vis d'Onyxia, chaque action effectuée par l'utilisateur via l'interface utilisateur est accompagnée de la commande exacte exécutée sur le cluster Kubernetes sous-jacent.

Si le projet Onyxia a été initialement développé afin de permettre l'expérimentation avec des outils de *data science* à l'état de l'art, les environnements qu'il permet de mettre à disposition ne se veulent pas pour autant élitistes. Un objectif majeur du projet est de couvrir une large gamme de besoins exprimés par les statisticiens, de la production statistique courante réalisée en *self* aux usages les plus expérimentaux. Ainsi, cohabitent dans le catalogue de services des environnements de développement usuels — RStudio pour l'usage de R, Jupyter et VSCode pour l'usage de Python — et des environnements pour des usages avancés, mais déployés à travers les mêmes environnements interactifs. Par exemple, lancer des traitements distribués avec Spark en Python se fera également à travers l'usage de Jupyter ou VSCode ; les services de base peuvent ainsi servir de porte d'entrée à des usages plus avancés par la suite. Du fait de la diversité des besoins couverts, les bénéfices à migrer seront différenciés selon les profils. Les utilisateurs dont les besoins actuels sont déjà bien couverts par les infrastructures de *self* existantes bénéficieraient essentiellement de la capacité à spécifier finement les ressources allouées à leur service et ainsi limiter les risques de rentrer en concurrence avec les processus d'autres utilisateurs en cas de saturation de la machine. Les bénéfices à migrer seront en revanche beaucoup plus marqués pour les utilisateurs souhaitant aller plus loin et développer de véritables prototypes d'applications pour leurs projets : configurer des scripts d'initialisation pour adapter les environnements à leurs besoins, déployer une application interactive (par exemple, en R Shiny) pour publier des visualisations de données dynamiques, ou encore déployer des services sur-mesure comme des bases de données à la demande ou bien des protoypes d'API. Pour permettre à ces utilisateurs avancés, souvent limités par la rigidité des environnements de calculs traditionnels, de continuer à faire progresser la structure via des usages innovants, Onyxia offre — selon la politique de sécurité de l'organisation — de larges possibilités de configuration des services et un accès étendu au cluster Kubernetes sous-jacent. Cela signifie que les utilisateurs peuvent ouvrir librement un terminal sur un service interactif et interagir avec le cluster — dans les limites de leur *namespace* — afin d'appliquer des ressources personnalisées et déployer des applications ou d'autres usages de leurs choix.

Au-delà de l'autonomie et de la scalabilité, les choix architecturaux d'Onyxia favorisent également la reproductibilité des calculs statistiques et la portabilité des applications. Dans le paradigme des conteneurs, l'utilisateur doit apprendre à gérer des ressources qui sont par nature éphémères, puisqu'elles n'existent qu'au moment de leur mobilisation effective dans le cadre d'un traitement. Cette non-persistance implique une séparation claire du code — hébergé sur une forge de code, comme GitLab ou GitHub — des données — stockées sur une solution de stockage spécifique, comme MinIO — et de la configuration et des secrets — passés au conteneur sous la forme de variables d'environnement. Au moment du lancement du traitement, le conteneur doit récupérer ces différents éléments (entrées), et produit par construction les mêmes sorties (production de données, modifications dans une base de données, visualisations, etc.) à partir d'un même jeu d'entrées. Cette séparation est un critère fondamental de qualité des projets de code dans la mesure où elle favorise à la fois la reproductibilité et de portabilité. Un conteneur étant nécessairement identifié par un *tag* (label), il est possible dans ce paradigme de versionner non plus seulement le code d'un projet, mais l'ensemble de l'environnement d'exécution qui garantit la reproduction des résultats obtenus à partir des mêmes données en entrée, ce qui constitue un gage de reproductibilité du chiffre statistique. Par ailleurs, le fait de développer dans des services conteneurisés favorise fortement la portabilité des projets, c'est à dire leur capacité à s'exécuter de manière homogène quelle que soit l'infrastructure de calcul sous-jacente. Ainsi, et sous réserve d'un accès homogène aux données d'entrée et aux ressources de calcul, un conteneur s'étant exécuté correctement sur une infrastructure de développement en *self* s'exécutera de la même manière sur une infrastructure de production. La conteneurisation permet donc fondamentalement de réduire l'écart existant entre les infrastructures de développement et les infrastructures de production, limitant ainsi les coûts de développement supplémentaires qui caractérisent souvent le passage en production des projets. Cette technologie peut également permettre d'envisager des modes de collaboration plus continus entre les équipes métiers et informatiques. Le fait de s'échanger des conteneurs, c'est à dire des environnements dont on garantit le fonctionnement, plutôt que du code seul, rarement portable en soi, permet aux différentes parties prenantes de se spécialiser sur leur cœur de métier : la spécification, l'écriture de la logique métier, et le débogage éventuel côté équipe métier ; le développement applicatif, les tests fonctionnels et le *monitoring* côté informatique — limitant par là le besoin coûteux mais fréquent de fait de recoder des applications d'un langage statistique vers un langage informatique.

## Un large catalogue de services pour couvrir le cycle de vie des projets de *data science* {#sec-catalog}

L'intention du projet Onyxia était de fournir aux statisticiens un environnement complet conçu pour accompagner le développement de bout en bout des projets de *data science*. Comme illustré dans @fig-onyxia-catalog, le catalogue par défaut propose une vaste gamme de services couvrant l'ensemble du cycle de vie d'un projet, du développement à la diffusion.

![Le catalogue d'Onyxia vise à couvrir l'ensemble du cycle de vie des projets de data science](../../figures/onyxia-catalog.svg){#fig-onyxia-catalog}

L'utilisation principale de la plateforme est le déploiement d'environnements de développement interactifs (IDE), tels que RStudio, Jupyter ou VSCode. Ces IDE sont voulus comme étant "prêts à l'emploi" : ils sont équipés des dernières versions des principaux langages de programmation *open source* couramment utilisés par les statisticiens publics (R, Python, SQL, Julia) ainsi que des librairies les plus fréquemment utilisées pour chaque langage. Afin de garantir que les services restent à jour et cohérents entre eux, l'Insee maintient un dépôt d'images Docker sous-jacentes et les met à jour chaque semaine. Ces images sont entièrement *open source*[^images-datascience] et peuvent donc être réutilisée en dehors du projet.

Comme décrit dans les sections précédentes, la couche de persistance de ces environnements interactifs est principalement assurée par MinIO, une solution de stockage objet *open source*. Cette solution étant basée sur une API REST standardisée, les fichiers peuvent être facilement interrogés depuis R ou Python à l'aide de librairies de haut niveau. Cela représente en soi une étape importante pour garantir la reproductibilité : les données ne sont pas sauvegardées localement, puis appelées via des chemins propres à une infrastructure ou un système de fichiers particulier. Au contraire, les requêtes aux fichiers sont spécifiées sous forme de requêtes HTTP standards, rendant la structure globale des projets plus évolutive. Les traitements rencontrés dans le service statistique public reposant très largement sur des fichiers de données, le paradigme du stockage objet répond très bien aux besoins de la plupart des projets que nous accompagnons sur ces infrastructures. Des services de bases de données supplémentaires, tels que PostgreSQL et MongoDB, sont également proposés pour les applications ayant des besoins spécifiques, notamment celles nécessitant de traitement géospatial en base (PostGIS) ou un stockage de données orienté documents.

Onyxia ayant été développé afin de permettre l'expérimentation avec des sources de données volumineuses, le catalogue propose également des services facilitant le passage à l'échelle. Pour les projets faisant intervenir des données volumineuses — de l'ordre de dizaines ou de centaines de millions de ligne — les différents services disposent nativement des librairies Arrow et DuckDB, permettant de traiter efficacement les données stockées au format Parquet en mémoire (cf. section XXX). Pour des usages plus conséquents, faisant intervenir des données massives, des logiciels comme Spark et Trino permettent d'effectuer des calculs distribués au sein d'un cluster Kubernetes via un simple lancement de service interactif ou d'un *batch* de traitement. Dans les deux cas, ces services sont préconfigurés pour s'intégrer naturellement avec le stockage S3, facilitant ainsi la création de *pipelines* de données à la fois efficients et intégrés de bout en bout. Enfin, différents services pré-configurés pour l'utilisation d'une GPU sont également proposés pour les projets basés sur des méthodes d'apprentissage automatique intensives en calcul. Le catalogue d'Onyxia fournit donc un point d'entrée unique pour mettre à disposition ces ressources rares ainsi que des librairies spécialisées — par exemple, les librairies de *deep learning* PyTorch et Tensorflow — avec la même simplicité que le lancement d'un service interactif de base.

Au-delà de la phase expérimentation, l'objectif est également de permettre aux statisticiens de produire des projets dits de "quasi-prod", au sens où ils préfigurent un passage en production afin d'en faciliter sa réalisation. Conformément aux principes de l'approche *DevOps*, cela implique de faciliter le déploiement de prototypes et leur amélioration continue au fil du temps. À cette fin, le catalogue d'Onyxia propose un ensemble de services *open source* visant à automatiser et industrialiser le processus de déploiement d'applications (ArgoCD), ordonnancer des traitements séquentiels et/ou parallèles (Argo-Workflows), ou encore déployer et gérer le cycle de vie des modèles d'apprentissage automatique (MLflow). La [Section 4](../mlops/index.qmd#sec-mlops) illustre comment ces outils ont joué un rôle central dans la mise en production de premiers modèles d'apprentissage automatique à l’Insee, conformément aux principes du MLOps.

Dans la @sec-principles-autonomy-fr, nous avons souligné qu'un des principes fondamentaux d'Onyxia était d'éviter l'enfermement propriétaire. Dans cette optique, les organisations qui instancient Onyxia sont libres de personnaliser les catalogues pour répondre à leurs besoins spécifiques, ou même de créer leurs propres catalogues indépendamment de l'offre par défaut. Cette flexibilité garantit aux organisations le fait de ne pas être limité à une solution ou à un fournisseur unique, et ainsi de pouvoir adapter la plateforme à l'évolution de leurs besoins ou de migrer vers une autre solution *cloud* dans le futur si nécessaire.

## Construire des communs numérique : un projet, plusieurs instances

En tant qu'initiative entièrement *open source*, le projet Onyxia vise à construire des "communs numériques" en promouvant et en développant des logiciels facilement réutilisables dans le service statistique publique et plus largement [@schweik2006free]. Cela concerne, tout d'abord, les composants sur lesquels repose Onyxia : à la fois ses briques technologiques (Kubernetes, MinIO, Vault) de même que l'ensemble des services du catalogue sont *open source*. De même, le code source du projet Onyxia est disponible publiquement sur GitHub[^onyxia-github] sous licence MIT ce qui, associé à une documentation détaillée[^onyxia-docs], favorise les réutilisations du projet. Enfin, cette orientation est sensible à travers les principes architecturaux qui ont guidé le développement du projet. La notion de "région", qui permet de paramétriser finement la configuration du logiciel et son interaction avec le cluster Kubernetes sous-jacent, la possibilité de définir simplement des identités graphiques spécifiques (voir @fig-onyxia-instances), et la possibilité d'adapter la catalogue de services (cf. supra) facilitent les ré-instanciations et l'appropriation du projet par les organisations.

![Un projet, de multiples instances : l'interface web est adaptable à l'identité graphique de chaque organisation](../../figures/onyxia-instances.png){#fig-onyxia-instances}

Ainsi, deux instances d'Onyxia cohabitent actuellement à l'Insee, qui couvrent chacune des besoins différents. L'instance historique, nommée SSP Cloud, est une instance de démonstration du projet Onyxia. Equipée de ressources de calcul conséquentes[^cluster] et du catalogue de services le plus complet, cette plateforme est conçue comme un bac à sable permettant d'expérimenter en toute autonomie des nouvelles méthodes et outils de *data science*[@comte2022sspcloud]. Au-delà de ses capacités techniques, le SSP Cloud incarne les principes de l'innovation ouverte [@chesbrough2003open]. Déployé sur internet[^datalab], il est accessible non seulement aux agents de l'Insee mais également, plus largement, aux agents des ministères, aux universités et grandes écoles françaises et aux autres INS européens. La nature fondamentalement collaborative du SSP Cloud s'est avérée particulièrement bénéfique pour l'organisation d'événements innovants, tels que des hackathons — tant au niveau national qu'international — et dans le domaine académique. Il est devenu une ressource intégrale pour plusieurs universités et Grandes Écoles en France, favorisant l'utilisation d'environnements *cloud* et reproductibles, tout en évitant l'effet d'enfermement propriétaire dû à une dépendance excessive des institutions éducatives envers des solutions *cloud* propriétaires. En conséquence, la plateforme est désormais largement utilisée dans le service statistique publique français et plus largement, avec environ 1000 utilisateurs uniques par mois début 2025. Ces utilisateurs forment une communauté dynamique grâce à un canal de discussion centralisé[^tchap_sspcloud] ; ils contribuent à améliorer l'expérience utilisateur en signalant des bugs, en proposant de nouvelles fonctionnalités et en contribuant ainsi directement au projet.

Si le côté résolument ouvert du SSP Cloud rend cette instance particulièrement adaptée à la préfiguration de nouveaux usages, il impose en contrepartie l'utilisation de données ouvertes dans les projets qui y sont menés. A ce titre, cette instance ne pouvait servir plateforme de traitements de données confidentielles à l'Insee. 

Associée à une  cette transparence facilite grandement la possibilité pour d'autres organisations de créer des instances de plateformes de *data science* basées sur le logiciel Onyxia et de les adapter à leurs besoins spécifiques (voir @fig-onyxia-instances).  Cela a permis au projet d'attirer une communauté croissante de contributeurs issus des statistiques publiques (Statistique Norvège), des ONG (Mercator Ocean[^mercator]), des centres de recherche et même de l'industrie, favorisant ainsi une transition progressive vers une gouvernance plus décentralisée du projet. Dans les prochaines années, l'implication des INS (Instituts Nationaux de Statistique) du système statistique européen devrait augmenter, puisque le SSPCloud a été choisie comme plateforme *data science* de référence dans le cadre du projet AIML4OS[^aiml4os].


[^mercator]: Lien vers l'instance Onyxia de Mercator Ocean : [https://datalab.dive.edito.eu/]()
[^onyxia-github]: [https://github.com/InseeFrLab/onyxia]()
[^onyxia-docs]: [https://docs.onyxia.sh/]()
[^aiml4os]: Plus d'informations à propos de ce projet disponibles à [https://cros.ec.europa.eu/dashboard/aiml4os]()
[^cluster]: Sur le plan matériel, le SSP Cloud est constitué d'un cluster Kubernetes d'environ 20 serveurs, pour une capacité totale de 10 To de RAM, 1100 processeurs, 34 GPU et 150 To de stockage.
[^datalab]: [https://datalab.sspcloud.fr/]()

[^tchap_sspcloud]: Lien vers les canaux de discussion [https://www.tchap.gouv.fr/#/room/#SSPCloudXDpAw6v:agent.finances.tchap.gouv.fr](Tchap) et [https://join.slack.com/t/3innovation/shared_invite/zt-19tht9hvr-bZGMdW8AV_wvd5kz3wRSMw](Slack)



::: 
