---
number-offset: 4
---

# Discussion

Le développement des méthodes de *data science* offre un potentiel considérable pour la statistique publique. Cependant, notre capacité à tirer profit de ces nouvelles méthodes dépend essentiellement de notre aptitude à produire des chaînes de production de qualité, robustes et adaptés à leurs objectifs. Cette évolution nécessite une réflexion approfondie sur ce qui constitue une infrastructure moderne et évolutive pour la *data science* dans le domaine des statistiques publiques. Cet article présente le projet Onyxia, une proposition pour une telle plateforme développée à l'Insee. En exploitant des technologies *cloud* devenues des standards dans l'écosystème de la donnée, le projet vise à accroître l'autonomie des statisticiens dans l'orchestration de leurs traitements statistiques, tout en favorisant la reproductibilité des statistiques produites. Les technologies *cloud* étant notoirement difficiles à configurer, la valeur principale d’Onyxia réside dans leur accessibilité pour les statisticiens grâce à une interface ergonomique, simple d'utilisation, et un catalogue de services préconfigurés couvrant les usages les plus courants d'un statisticien public. À travers un projet interne visant à refondre le processus de codification de l'Activité Principale de l'Entreprise (APE) en utilisant des méthodes d'apprentissage automatique, nous illustrons comment Onyxia permet de construire de manière itérative des projets de *machine learning* prêts à passer en production, favorisant l'amélioration continue, un principe fondamental de l'approche MLOps.

Initialement développé comme un projet interne, Onyxia a acquis une reconnaissance dépassant le cadre de l'Insee ou de l'administration française. Convaincues du potentiel des technologies *cloud* pour renforcer l'autonomie et exploiter pleinement le potentiel de la *data science*, plusieurs organisations disposent désormais d'une instance de production d'Onyxia (comme c'est le cas à l'Insee avec le déploiement récent de $LS^3$), et de nombreuses autres sont en phase de test ou d'implémentation. Par ailleurs, le choix d’Onyxia comme plateforme de *data science* de référence dans le cadre du projet AIML4OS devrait encore accroître son adoption au sein du SSE. Cette tendance est naturellement très bénéfique pour le projet Onyxia, qui passe d’un projet développé en *open source* — mais principalement à l’Insee — à un véritable projet *open source* avec une base croissante de contributeurs. Cela, en retour, facilite son adoption par d'autres organisations, en offrant davantage de garanties sur sa pérennité indépendamment de la stratégie de l'Insee. La gouvernance du projet évolue actuellement pour refléter cette tendance, notamment avec l'organisation de réunions communautaires mensuelles et la création d’un canal public et d’une feuille de route pour le projet[^onyxia-project].

[^onyxia-project]: Toutes les informations sont disponibles sur le dépôt GitHub du projet : [https://github.com/InseeFrLab/onyxia]()

Malgré ce succès, nous constatons plusieurs limites à l'adoption généralisée du projet au sein des organisations. Tout d'abord, il est essentiel de rappeler que le choix fondamental fait par les organisations qui adoptent Onyxia ne porte pas sur le logiciel en lui-même, mais sur les technologies sous-jacentes : la conteneurisation (via Kubernetes) et le stockage d'objets. Ces technologies peuvent représenter des coûts d'entrée important pour les organisations, puisqu'elles nécessitent un investissement dans le développement et le maintien de compétences qui ne sont pas toujours présentes dans les INS. Cependant, on constate que les organisations qui manipulent de la donnée tendent de plus en plus à s'orienter vers des solutions *cloud* qui pourrait atténuer ces défis à long terme.

De même, la transition vers les technologies *cloud* impose des coûts d'entrée pour les statisticiens. Tout d'abord, ils sont souvent confrontés à une perte de repères quant à l'endroit où les calculs sont réellement effectués : bien qu'ils soient habitués à effectuer des calculs sur des serveurs centralisés plutôt que sur un ordinateur personnel, le conteneur ajoute une couche d'abstraction qui rend cet emplacement difficile à appréhender au départ. Mais le changement le plus perturbant dans ce paradigme est la perte de persistance des données. Dans les configurations traditionnelles — qu'il s'agisse d'un ordinateur personnel ou d'un serveur accessible via un bureau virtuel — le code, les données et l'environnement de calcul sont souvent mélangés dans une sorte de boîte noire. À l'inverse, les conteneurs, par construction, n'ont pas de persistance. Si le stockage d'objets fournit cette persistance, une utilisation adéquate de ces infrastructures  exige une variété d'outils et de compétences : utilisation d'un système de contrôle de version pour le code (e.g. Git), interaction avec l'API de stockage d'objets pour enregistrer les données, gestion de fichiers de configuration et/ou de secrets et variables d'environnement, etc. En un sens, ces coûts d'entrée peuvent être considérés comme le « prix » de l'autonomie : grâce aux technologies *cloud*, les statisticiens ont désormais accès à des environnements évolutifs et flexibles leur permettant d’expérimenter plus librement, mais cette autonomie exige une montée en compétences significative, qui peut être intimidante et, *in fine*, limiter cette adoption. Cependant, notre expérience à l'Insee montre que cet effet peut être largement atténué grâce à une combinaison de formation des statisticiens aux bonnes pratiques de développement et d’accompagnement des projets statistiques lors de leur transition vers des infrastructures *cloud*.

Bien qu'Onyxia ait significativement démocratisé l'accès aux technologies *cloud* pour les statisticiens, l'intégration effective des méthodes de *data science* dans la production statistique des INS soulève des défis plus larges, d'ordre organisationnel. Une leçon majeure tirée du déploiement de notre premier modèle de *machine learning* en production est la nécessité de surmonter la segmentation des compétences entre les équipes informatiques, métier et innovation. Par nature, les projets de *machine learning*, pour pouvoir passer en production, impliquent un large éventail de compétences — connaissance du domaine métier, entraînement et amélioration des modèles ainsi que leur déploiement et supervision — et nécessitent donc une collaboration efficace entre des professionnels aux cultures de travail et langages de programmation variés. Notre expérience montre que les technologies *cloud*, en favorisant l'autonomie des *data scientists*, apportent plus de continuité aux projets d'apprentissage automatique et facilitent cette collaboration essentielle entre les différents profils. Toutefois, répondre pleinement à ces défis nécessite des choix qui dépassent le domaine technique. Par exemple, intégrer certaines compétence en *data science* directement au sein des équipes métier, en complément des équipes d'innovation centralisées, pourrait favoriser une meilleure collaboration. De même, recruter des profils qui ne sont pas traditionnellement présents dans les INS, comme les *data engineers* ou les *ML engineers*, pourrait apporter de nouvelles compétences à l'intersection des méthodologies statistiques et des techniques informatiques. Au final, la transition vers une approche axée sur la *data science* dans la production statistique doit s'appuyer sur une stratégie équilibrée qui lie des solutions techniques comme Onyxia avec des ajustements organisationnels et humains, favorisant une culture de collaboration, de formation continue et d’innovation.
