<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>index – DT Cloud &amp; Production Statistique</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../src/implementation/index.html" rel="next">
<link href="../../src/introduction/index.html" rel="prev">
<link href="../../images/favicon.ico" rel="icon">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-44d8862ff5335838008e1d1029e4056f.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../../styles/styles.css">
</head>

<body class="nav-sidebar docked">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../src/principles/index.html">2 - Principes</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
    <div class="pt-lg-2 mt-2 text-center sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../../">DT Cloud &amp; Production Statistique</a> 
        <div class="sidebar-tools-main">
    <a href="../../src/pdf-fr/index.pdf" title="PDF" class="quarto-navigation-tool px-1" aria-label="PDF"><i class="bi bi-file-pdf-fill"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../src/introduction/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">1 - Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../src/principles/index.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">2 - Principes</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../src/implementation/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">3 - Implémentation</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../src/mlops/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">4 - MLOps</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../src/discussion/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">5 - Discussion</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#sec-principles-fr" id="toc-sec-principles-fr" class="nav-link active" data-scroll-target="#sec-principles-fr"><span class="header-section-number">2</span> Construire un environnement de <em>data science</em> moderne grâce aux technologies cloud</a>
  <ul class="collapse">
  <li><a href="#sec-limites-archi-big-data" id="toc-sec-limites-archi-big-data" class="nav-link" data-scroll-target="#sec-limites-archi-big-data"><span class="header-section-number">2.1</span> Limites des architectures informatiques traditionnelles</a></li>
  <li><a href="#sec-cloud-native-fr" id="toc-sec-cloud-native-fr" class="nav-link" data-scroll-target="#sec-cloud-native-fr"><span class="header-section-number">2.2</span> L’apport des technologies <em>cloud</em></a></li>
  <li><a href="#les-technologies-cloud-favorisent-lautonomie-et-la-reproductibilité" id="toc-les-technologies-cloud-favorisent-lautonomie-et-la-reproductibilité" class="nav-link" data-scroll-target="#les-technologies-cloud-favorisent-lautonomie-et-la-reproductibilité"><span class="header-section-number">2.3</span> Les technologies <em>cloud</em> favorisent l’autonomie et la reproductibilité</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block"></header>




<section id="sec-principles-fr" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Construire un environnement de <em>data science</em> moderne grâce aux technologies cloud</h1>
<p>L’intégration des nouvelles sources de données et des méthodologies innovantes dans les processus de production statistique pose plusieurs défis. Le premier est celui de l’infrastructure : ces sources de données sont souvent massives, donc coûteuses en stockage, et les méthodologies permettant de les traiter sont généralement gourmandes en ressources de calcul. L’autre défi est de permettre aux statisticiens d’accéder à ces ressources à travers des environnements qui favorisent l’autonomie — qu’il s’agisse de dimensionner les ressources de calcul en fonction des chaînes de productions statistiques à traiter, de déployer des preuves de concept avec agilité, de travailler de manière collaborative, etc. Dans ce contexte, l’objectif est de concevoir une plateforme de <em>data science</em> qui non seulement rende possible le traitement des données massives, mais qui permette également aux statisticiens de tester et déployer de nouveaux outils de manière autonome. Pour se faire, la première étape a été d’analyser les évolutions de l’écosystème de la donnée afin d’en extraire les tendances significatives qui marquent les choix des organisations. L’analyse de ces évolutions indique une tendance générale vers l’adoption des technologies <em>cloud</em>, en particulier les conteneurs et le stockage objet, qui permettent de construire des infrastructures capables de gérer des ensembles de données volumineux et variés de manière flexible et efficiente. Ces technologies se révèlent particulièrement pertinentes pour construire des environnements de calcul destinés à la statistique publique, dans la mesure où elles favorisent l’autonomie et la reproductibilité des traitements.</p>
<section id="sec-limites-archi-big-data" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="sec-limites-archi-big-data"><span class="header-section-number">2.1</span> Limites des architectures informatiques traditionnelles</h2>
<p>Afin de comprendre la prédominance des technologies <em>cloud</em> dans les infrastructures actuelles de traitement de la donnée, il est nécessaire de rappeler l’historique — sans prétendre à l’exhaustivité — des architectures développées au cours des dernières décennies afin de traiter les données de plus en plus volumineuses générées par la numérisation des activités humaines. Historiquement, les données ont été stockées dans des bases de données, c’est à dire des systèmes de stockage et d’organisation de la donnée. Ces objets ont vu le jour dans les années 1950, et ont connu un essor particulier avec les bases de données relationnelles dans les années 1980. Cette technologie se révélant particulièrement pertinente pour organiser le stockage des données “métier” des entreprises, elle a été à la base des <em>data warehouses</em>, qui ont longtemps constitué la référence des infrastructures de stockage de la donnée. Si leur implémentation technique peut être de nature variée, leur principe est simple : des données de sources multiples et hétérogènes sont intégrées dans un système de bases de données relationnel selon des règles métier grâce à des processus dits <em>ETL</em> (<em>extract-transform-load</em>), afin de les rendre directement accessibles pour une variété d’usages (analyse statistique, <em>reporting</em>, etc.) à l’aide d’un langage normalisé : SQL <span class="citation" data-cites="chaudhuri1997overview">(<a href="#ref-chaudhuri1997overview" role="doc-biblioref">Chaudhuri and Dayal 1997</a>)</span>.</p>
<p>Au début des années 2000, la montée en puissance des usages de nature <em>big data</em> dans les entreprises met en lumière les limites des <em>data warehouses</em> traditionnels. D’une part, les données traités présentent une diversité croissante de formats (structurés, semi-structurés et non structurés), et cette réalité rentre difficilement dans le monde ordonné des <em>data warehouses</em>, qui nécessite de spécifier <em>a priori</em> le schéma des données. Pour pallier ces limites, de nouvelles infrastructures de stockage vont être développées : les <em>data lakes</em>, qui permettent la collecte et le stockage de quantités massives de données de nature diverse. D’autre part, la taille considérable de ces données rend de plus en plus difficile leur exploitation sur une unique machine. C’est dans ce contexte que Google publie le paradigme MapReduce <span class="citation" data-cites="ghemawat2003google dean2008mapreduce">(<a href="#ref-ghemawat2003google" role="doc-biblioref">Ghemawat, Gobioff, and Leung 2003</a>; <a href="#ref-dean2008mapreduce" role="doc-biblioref">Dean and Ghemawat 2008</a>)</span>, posant les bases d’une nouvelle génération de systèmes permettant de traiter de larges volumes de données de manière distribuée. Dans les infrastructures traditionnelles, le passage à l’échelle était réalisé selon un principe de scalabilité verticale, c’est à dire en augmentant la puissance d’une machine de calcul ou en choisissant une machine plus performante. Cette approche devient néanmoins rapidement très coûteuse et se heurte aux limites physiques des composants. A l’inverse, les architectures distribuées adoptent le principe de scalabité horizontale : en installant des serveurs — chacun d’une puissance limitée — en parallèle et en adaptant les algorithmes à cette logique distribuée, on parvient à traiter des données massives avec du matériel standard. Dans la lignée de ces travaux, émerge l’écosystème Hadoop qui offre une combinaison de technologies complémentaires : un <em>data lake</em> (HDFS - <em>Hadoop Distributed File System</em>), un moteur de calcul distribué (MapReduce) et des outils d’intégration et de transformation de la donnée. Cet écosystème est progressivement complété par des outils qui vont démocratiser la capacité à traiter des données <em>big data</em> : Hive, qui convertit des requêtes SQL en traitements MapReduce distribués, puis Spark, qui lève certaines limites techniques de MapReduce et fournit des API dans plusieurs langages (Java, Scala, Python, etc.). Le succès de l’écosystème Hadoop dans les entreprises est considérable dans la mesure où il permet de traiter des volumes de données sans précédent — jusqu’au péta-octet — et des vélocités considérables — jusqu’au temps réel — à l’aide de langages de programmation non réservés aux seuls informaticiens.</p>
<p>À la fin des années 2010, les architectures basées sur Hadoop connaissent néanmoins un net déclin de popularité. Dans les environnements Hadoop traditionnels, le stockage et le calcul sont co-localisés par construction : si les données à traiter sont réparties sur plusieurs serveurs, chaque section des données est directement traitée sur la machine hébergeant cette section, afin d’éviter les transferts réseau entre serveurs. Dans ce paradigme, la mise à l’échelle de l’architecture implique une augmentation linéaire à la fois des capacités de calcul et de stockage, indépendamment de la demande réelle. Dans un article volontairement provocateur et intitulé “<em>Big Data is Dead</em>” <span class="citation" data-cites="Tigani_2023">(<a href="#ref-Tigani_2023" role="doc-biblioref">Tigani 2023</a>)</span>, Jordan Tigani, l’un des ingénieurs fondateurs de Google BigQuery, explique pourquoi ce modèle ne correspond plus à la réalité de la plupart des organisations exploitant intensivement de la donnée. Premièrement, parce que “dans la pratique, la taille des données augmente beaucoup plus rapidement que les besoins en calcul”. Même si la quantité de données générées et nécessitant donc d’être stockées croît de manière rapide au fil du temps, il n’est généralement pas nécessaire d’interroger l’ensemble des données stockés mais seulement les portions les plus récentes, ou seulement certaines colonnes et/ou groupes de lignes. Par ailleurs, Tigani souligne que “la frontière du <em>big data</em> ne cesse de reculer” : les avancées dans les capacités des serveurs et la baisse des coûts du matériel signifient que le nombre de charges de travail ne tenant pas sur une seule machine — une définition simple mais efficace du <em>big data</em> — a diminué de manière continue. En conséquence, en séparant correctement les fonctions de stockage et de calcul, même les traitements de données substantiels peuvent finir par utiliser “beaucoup moins de calcul que prévu […] et pourraient même ne pas avoir besoin d’un traitement distribué du tout”. Ces enseignements plaident donc de manière générale pour le choix d’infrastructures dans lesquelles ressources de calcul et de stockage sont le plus faiblement couplées possibles.</p>
<p>Cette tendance est par ailleurs renforcée par certaines avancées technologiques récentes issues de l’écosystème de la donnée qui permettent de traiter des volumes de plus en plus importants de données sur des machines standards en utilisant des langages de programmation usuels comme R ou Python. Une première innovation concerne l’apparition de formats de stockage beaucoup plus efficients que les formats traditionnels, comme Apache Parquet <span class="citation" data-cites="parquet2013">(<a href="#ref-parquet2013" role="doc-biblioref">Foundation 2013</a>)</span>. Ce format de stockage orienté-colonne (voir <a href="#fig-columnar-storage" class="quarto-xref">Figure&nbsp;1</a>) est notamment optimisé pour les analyses <em>WORM</em> (<em>write once, read many</em>). Il est ainsi particulièrement adapté aux traitements statistiques, où les données sont généralement figées après la collecte, mais les analyses ultérieures à partir de ces données potentiellement nombreuses. De plus, la possibilité de partitionner ces données selon une variable de filtrage fréquente, comme la région ou le département par exemple, permet d’optimiser les traitements — à la manière d’un index dans une base SQL — et d’accroître encore leur efficience. Ces différentes propriétés rendent le format Parquet très pertinent pour les traitements analytiques qui caractérisent la production de statistique publique <span class="citation" data-cites="dondon2023quels abdelaziz2023optimizing">(<a href="#ref-dondon2023quels" role="doc-biblioref">Dondon and Lamarche 2023</a>; <a href="#ref-abdelaziz2023optimizing" role="doc-biblioref">Abdelaziz et al. 2023</a>)</span>.</p>
<div id="fig-columnar-storage" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-columnar-storage-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../../figures/columnar-storage.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-columnar-storage-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Représentation orientée ligne et orientée colonne d’un même jeu de données.
</figcaption>
</figure>
</div>
<p>Note: De nombreuses opérations statistiques sont analytiques (dites OLAP - <em>Online Analytical Processing</em>) par nature : elles impliquent la sélection de colonnes spécifiques, le calcul de nouvelles variables, la réalisation d’agrégations basées sur des groupes, etc. Le stockage orienté ligne - comme dans un fichier CSV - n’est pas adapté à ces opérations analytiques, car il nécessite de charger l’ensemble du jeu de données en mémoire afin d’effectuer une requête. À l’inverse, le stockage orienté colonne permet de ne lire que les colonnes de données pertinentes, ce qui réduit considérablement les temps de lecture et de traitement pour ces charges de travail analytiques. En pratique, les formats colonnes populaires tels que Parquet utilisent une représentation hybride : ils sont principalement orientés colonne, mais intègrent également un regroupement astucieux basé sur les lignes pour optimiser les requêtes de filtrage.</p>
<p>Le format Parquet rend le stockage de données au format tabulaire beaucoup plus efficient. Mais pour pleinement bénéficier de cette structure de données, il est également nécessaire de s’intéresser à l’étape suivante : le traitement des données en mémoire. Deux outils majeurs ont émergé à cette fin au cours des dernières années. Le premier est Apache Arrow, un format tabulaire de données en mémoire interopérable entre de nombreux langages (Python, R, Java, etc.). Le second est DuckDB, un système de base de données portable et également interopérable. Ces deux outils, bien que techniquement très différents en termes d’implémentation, présentent des avantages et des gains de performance semblables. D’abord, ils sont tous deux orientés-colonne (voir <a href="#fig-columnar-storage" class="quarto-xref">Figure&nbsp;1</a>) et travaillent ainsi en synergie avec le format Parquet, dans la mesure où ils font persister les bénéfices de ce format de stockage dans la mémoire. Par ailleurs, ils permettent tout deux d’augmenter considérablement les performances des requêtes sur les données grâce à l’utilisation de la <em>lazy evaluation</em> (“évaluation paresseuse”). Là où les opérations sur des données sont généralement exécutées de manière linéaire par les langages de programmation — par exemple, sélectionner des colonnes et/ou filtrer des lignes, puis calculer de nouvelles colonnes, puis effectuer des agrégations, etc. — Arrow comme DuckDB exécutent quant à eux ces dernières selon un plan d’exécution pré-calculé qui optimise de manière globale la chaîne de traitements. Dans ce paradigme, les calculs sont non seulement beaucoup plus performants, mais également beaucoup plus efficients dans la mesure où ils n’impliquent de récupérer que les données effectivement nécessaires pour les traitements demandés. Ces innovations permettent ainsi d’envisager des traitements basés sur des données dont le volume total dépasse la mémoire RAM effectivement disponible sur une machine.</p>
</section>
<section id="sec-cloud-native-fr" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="sec-cloud-native-fr"><span class="header-section-number">2.2</span> L’apport des technologies <em>cloud</em></h2>
<p>Dans la lignée des observations de Tigani, on observe ces dernières années une transition marquée des organisations vers des architectures plus flexibles et faiblement couplées. L’avènement des technologies <em>cloud</em> a joué un rôle déterminant dans cette transition, et ce pour plusieurs raisons. D’abord, une raison technique : par rapport à l’époque où Hadoop constituait l’infrastructure <em>big data</em> de référence, la latence des flux réseaux est devenue une préoccupation bien moindre, rendant le modèle de co-localisation du stockage et des ressources de calcul sur de mêmes machines moins pertinent. Ensuite, une raison liée aux usages : si le volume des données générées continue de croître, c’est surtout la diversification des données exploitées qui marque l’évolution récente de l’écosystème. Les infrastructures modernes doivent doivent non seulement être capables de traiter de grands volumes, mais aussi être adaptables sur de multiples dimensions. Elles doivent pouvoir prendre en charge diverses structures de données (allant des formats structurés et tabulaires aux formats non structurés comme le texte, les images, le son et la vidéo) et permettre une large gamme de techniques computationnelles, du calcul parallèle aux modèles d’apprentissage profond qui nécessitent des GPU, ainsi que le déploiement et la gestion d’applications <span class="citation" data-cites="li2020big">(<a href="#ref-li2020big" role="doc-biblioref">Li et al. 2020</a>)</span>. Ces dernières années, deux technologies intimement liée au <em>cloud</em> — justifiant leur qualificatif de technologies <em>cloud-native</em> — ont émergé comme des solutions essentielles pour atteindre ce besoin d’environnements de calcul plus flexibles : la conteneurisation et le stockage objet.</p>
<p>Dans un environnement <em>cloud</em>, l’ordinateur de l’utilisateur devient un simple point d’accès pour effectuer des calculs sur une infrastructure centralisée. Cela permet à la fois un accès universel aux ressources et un passage à l’échelle des services, car il est plus facile de faire passer à l’échelle une infrastructure centrale — là encore de manière horizontale, c’est-à-dire en ajoutant davantage de serveurs. Cependant, ces infrastructures centralisées présentent deux limites importantes : la concurrence entre utilisateurs pour l’accès aux ressources physiques et la nécessité d’isoler correctement les applications déployées. Le choix de la conteneurisation est fondamental, car il répond à ces deux enjeux <span class="citation" data-cites="bentaleb2022containerization">(<a href="#ref-bentaleb2022containerization" role="doc-biblioref">Bentaleb et al. 2022</a>)</span>. En créant des “bulles” spécifiques à chaque service, les conteneurs garantissent l’herméticité des applications tout en restant légers, puisqu’ils partagent le système d’exploitation avec la machine hôte (voir <a href="#fig-containers" class="quarto-xref">Figure&nbsp;2</a>). Initialement développés dans le cadre du noyau Linux, les conteneurs ont fortement gagné en popularité au début des années 2010 grâce au moteur Docker qui a permis la démocratisation de leur utilisation - à tel point que l’on emploie parfois le terme “<em>dockerisation</em>” pour désigner la <em>conteneurisation</em>.</p>
<div id="fig-containers" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-containers-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../../figures/containers.png" class="img-fluid figure-img" style="width:65.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-containers-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Architecture d’un environnement conteneurisé.
</figcaption>
</figure>
</div>
<p>Note: Un conteneur est un groupe logique de ressources permettant d’encapsuler une application (par exemple, un <em>batch</em> R), les bibliothèques utilisées (ggplot, dplyr, etc.) et les librairies système nécessaires (l’interpréteur R, d’autres bibliothèques dépendantes du système d’exploitation, etc.) dans un contenant auto-suffisant. Les applications conteneurisées sont isolées les unes des autres grâce à la virtualisation, qui permet d’attribuer des ressources physiques spécifiques à chaque application tout en garantissant leur herméticité. Contrairement aux machines virtuelles (VM), qui virtualisent également le système d’exploitation (OS), les conteneurs s’appuient sur une forme de virtualisation légère : le conteneur partage l’OS de l’infrastructure hôte via le moteur de conteneurisation, dont le plus connu est Docker. En conséquence, les conteneurs sont beaucoup plus portables que les VM et peuvent être déployés et redistribués facilement.</p>
<p>Pour gérer plusieurs applications conteneurisées de manière systématique, les infrastructures conteneurisées s’appuient généralement sur un logiciel orchestrateur — le plus utilisé étant Kubernetes, un projet open source initialement développé par Google pour gérer ses nombreuses charges de travail conteneurisées en production <span class="citation" data-cites="vano2023cloud">(<a href="#ref-vano2023cloud" role="doc-biblioref">Vaño et al. 2023</a>)</span>. Les orchestrateurs automatisent le processus de déploiement, de mise à l’échelle et de gestion des applications conteneurisées, coordonnant leur exécution sur différents serveurs. Cette propriété permet notamment de traiter de très grands volumes de données de manière distribuée : les conteneurs décomposent les opérations de traitement des données massives en une multitude de petites tâches, organisées par l’orchestrateur. Cela minimise les ressources requises tout en offrant une flexibilité supérieure aux architectures basées sur Hadoop <span class="citation" data-cites="zhang2018comparative">(<a href="#ref-zhang2018comparative" role="doc-biblioref">Zhang et al. 2018</a>)</span>. Cette transition s’est d’ailleurs observée de manière très empirique à l’Insee dans le cadre du projet d’exploitation des données de caisse. Face aux difficultés computationnelles que posaient l’utilisation de ces données dans le calcul de l’IPC, un cluster Hadoop a d’abord été mis en place comme alternative à l’architecture existante. Une accélération des opérations de traitement des données pouvant aller jusqu’à un facteur 10 avait été observée, pour des opérations qui prenaient auparavant plusieurs heures <span class="citation" data-cites="leclair2019utiliser">(<a href="#ref-leclair2019utiliser" role="doc-biblioref">Leclair et al. 2019</a>)</span>. Malgré cette amélioration des performances, ce type d’architectures n’a pas été pérennisée, principalement du fait de leur complexité et donc de leur coût de maintenance. La solution finalement retenue a été de mettre en place un environnement Spark sur Kubernetes, permettant de bénéficier des gains de performance liés à la distribution des calculs tout en bénéficiant de la flexibilité des infrastructures <em>cloud</em>.</p>
<p>L’autre choix fondamental dans une architecture <em>cloud</em> concerne le mode de stockage des données. Les conteneurs étant par construction sans état (<em>stateless</em>), il est nécessaire de prévoir une couche de persistence pour stocker à la fois les données brutes en entrée des traitements et les données transformées en sortie de ces derniers. Dans l’écosystème des infrastructures de données conteneurisées, le stockage dit “objet” s’est progressivement imposé comme référence, largement popularisée par l’implémentation S3 (<em>Amazon Simple Storage Service</em>) d’Amazon <span class="citation" data-cites="samundiswary2017object">(<a href="#ref-samundiswary2017object" role="doc-biblioref">Samundiswary and Dongre 2017</a>)</span>. Afin de comprendre cette prédominance, il est utile de comparer ce mode de stockage aux autres modes existants.</p>
<p>Schématiquement, on peut distinguer trois grandes approches en matière de stockage : le stockage de fichiers (<em>filesystem</em>), le stockage par bloc (<em>block storage</em>) et le stockage d’objets (<em>object storage</em>). Le stockage de fichiers est le plus intuitif : les données sont organisées sous forme d’une structure hiérarchique de répertoires et de fichiers — comme sur un ordinateur personnel. Facile d’utilisation et adapté aux environnements traditionnels, ce mode de stockage passe difficilement à l’échelle et requiert des interventions manuelles pour monter et gérer les accès aux fichiers, ce qui restreint l’autonomie des utilisateurs et n’est pas adapté aux environnements de traitement éphémères comme les conteneurs. Le stockage par bloc propose un accès de bas niveau aux données sous forme de blocs contigus — à l’image du stockage sur un disque dur — garantissant des performances élevées et une faible latence. Il s’avère donc très pertinent pour des applications qui exigent un accès rapide aux données stockées, comme une base de données. En revanche, il passe là encore difficilement à l’échelle du fait du coût de la technologie et de la difficulté à faire croître horizontalement ce type de stockage. Enfin, le stockage objet divise quant à lui les fichiers de données en morceaux appelés “objets” qui sont ensuite stockés dans un référentiel unique, qui peut être distribué sur plusieurs machines. Chaque objet se voit attribuer un certain nombre de métadonnées (nom de l’objet, taille, date de création, etc.) dont un identifiant unique qui permet au système de retrouver l’objet sans la nécessité d’une structure hiérarchique comme celle d’un <em>filesystem</em>, ce qui réduit drastiquement le coût du stockage.</p>
<p>Les différentes propriétés du stockage objet le rendent particulièrement pertinent pour construire une infrastructure conteneurisée pour la <em>data science</em>. D’abord, il est optimisé pour la scalabilité : les objets stockés ne sont pas limités en taille et la technologie sous-jacente permet un stockage efficient de fichiers potentiellement très volumineux, si besoin en les distribuant horizontalement. Ensuite, il est source d’autonomie pour les utilisateurs : en stockant les données sous forme d’objets enrichis de métadonnées et accessibles via des API REST standardisées, il permet aux utilisateurs d’interagir directement avec le stockage via leur code applicatif (en R, Python, etc.) tout en offrant une gestion très fine des permissions — jusqu’aux droits sur un fichier — vie des jetons d’accès, garantissant ainsi une traçabilité accrue des opérations effectuées. Enfin, le stockage objet joue un rôle clé dans l’objectif de construction d’une infrastructure découplée comme celle évoquée précédemment. Dans la mesure où les dépôts de données — appelés <em>“buckets”</em> — sont interrogeables via des requêtes HTTP standards, les environnements de calcul peuvent importer par le biais du réseau les données nécessaires aux traitements réalisés. Ainsi, les ressources de stockage et de calcul n’ont plus besoin d’être sur les mêmes machines ni même nécessairement dans le même lieu, et peuvent ainsi évoluer indépendamment en fonction des besoins spécifiques de l’organisation.</p>
</section>
<section id="les-technologies-cloud-favorisent-lautonomie-et-la-reproductibilité" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="les-technologies-cloud-favorisent-lautonomie-et-la-reproductibilité"><span class="header-section-number">2.3</span> Les technologies <em>cloud</em> favorisent l’autonomie et la reproductibilité</h2>
<p>Comprendre comment les choix technologiques décrits dans la discussion technique ci-dessus se révèlent pertinents dans le contexte des statistiques publiques nécessite un examen critique de l’évolution des environnements informatiques mis à disposition des statisticiens à l’Insee.</p>
<p>À la fin des années 2000, alors que la micro-informatique est à son apogée, une grande partie des ressources techniques utilisées par les statisticiens sont locales : le code et les logiciels de traitement sont situés sur des ordinateurs personnels, tandis que les données sont accessibles via un système de partage de fichiers. En raison de la puissance limitée des ordinateurs personnels, cette configuration restreignait considérablement la capacité des statisticiens à expérimenter avec des sources <em>big data</em> ou des méthodes statistiques intensives en calculs. Par ailleurs, cet état de fait impliquait des risques de sécurité liés à la dissemination des données confidentielles au sein de l’organisation. Afin de pallier ces limites, une transition progressive est opérée vers des infrastructures centralisées avec le projet d’Architecture Unifiée Statistique (AUS). Ce centre de calcul propose une forme de transition entre une informatique locale et une informatique centralisée : elle concentre toutes les ressources sur des serveurs centraux, mais recrée l’expérience du poste de travail via un accès par bureau distant au centre de calcul. La centralisation des ressources de calcul et la technologie des coffres sécurisés permettent aux statisticiens d’effectuer des traitements en <em>self</em> sur des données à la fois volumineuses et confidentielles qui étaient jusqu’alors impossibles. A ce jour, AUS — dans sa troisième version — reste l’infrastructure de référence pour les traitements réalisés “en <em>self</em>” : les environnements disponibles couvrent une majorité des besoins des statisticiens et contribuent de manière essentielle à la production statistique de l’institut.</p>
<p>Bien que l’infrastructure informatique actuelle soutienne adéquatement les activités fondamentales de production statistique, elle restreint de manière notable la capacité des statisticiens à expérimenter librement et à innover. Le principal goulot d’étranglement dans cette organisation réside dans la dépendance des projets statistiques à la prise de décision centralisée en matière d’informatique, notamment en ce qui concerne l’allocation des ressources de calcul, l’accès au stockage partagé, l’utilisation de langages de programmation préconfigurés etc. En outre, ces dépendances conduisent souvent à un phénomène bien connu dans la communauté du développement logiciel, où les priorités des développeurs — itérer rapidement pour améliorer continuellement les fonctionnalités — entrent souvent en conflit avec l’objectif des équipes informatiques de garantir la sécurité et la stabilité des processus. À l’inverse, nous comprenons que les pratiques modernes en <em>data science</em> reflètent une implication accrue des statisticiens dans le développement et l’orchestration informatique de leurs opérations de traitement de données, au-delà de la simple phase de conception ou de validation. Les nouvelles infrastructures de <em>data science</em> doivent donc prendre en compte ce rôle élargi de leurs utilisateurs, en leur offrant plus d’autonomie que les infrastructures traditionnelles.</p>
<p>Nous soutenons que les technologies <em>cloud</em> sont une solution puissante pour offrir aux statisticiens une autonomie bien plus grande dans leur travail quotidien, favorisant ainsi une culture de l’innovation. Grâce au stockage objet, les utilisateurs obtiennent un contrôle direct sur la couche de stockage, leur permettant d’expérimenter avec des sources de données diverses sans être limités par les espaces de stockage souvent restreints et alloués par les départements informatiques. La conteneurisation permet aux utilisateurs de personnaliser leurs environnements de travail selon leurs besoins spécifiques — qu’il s’agisse de langages de programmation, de bibliothèques système ou de versions de packages — tout en leur offrant la flexibilité nécessaire pour adapter leurs applications à la puissance de calcul et aux capacités de stockage requises. Par construction, les conteneurs favorisent également le développement d’applications portables, permettant des transitions plus fluides entre les environnements de <em>self</em> et de production (<a href="#fig-containers" class="quarto-xref">Figure&nbsp;2</a>). Enfin, avec des outils d’orchestration tels que Kubernetes, les statisticiens peuvent déployer des applications interactives et des API comme preuves de concept, tout en automatisant le processus de construction. Cette capacité s’aligne avec l’approche DevOps, qui préconise la création de preuves de concept de manière itérative, plutôt que de chercher à développer la solution optimale (mais chronophage) pour un objectif préalablement défini <span class="citation" data-cites="leite2019survey">(<a href="#ref-leite2019survey" role="doc-biblioref">Leite et al. 2019</a>)</span>.</p>
<div id="fig-containers-portability" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-containers-portability-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="../../figures/containers-portability.png" class="img-fluid figure-img" style="width:85.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-containers-portability-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: Construction d’une image et déploiement d’un conteneur
</figcaption>
</figure>
</div>
<p>Note: Dans un environnement conteneurisé, les applications sont créées à partir de spécifications écrites dans des manifestes — un paradigme connu sous le nom d’<em>“infrastructure as code”</em>. Dans un <em>script</em>, conventionnellement nommé <em>Dockerfile</em>, les <em>data scientists</em> spécifient l’environnement de travail de leur application : le code de l’application, les logiciels à inclure (par exemple, R), les packages utilisés pour leurs opérations de traitement (par exemple, le package sf pour le calcul géospatial), ainsi que les librairies système dépendant de l’OS appelées par ces packages (par exemple GDAL, une bibliothèque standard pour traiter les formats utilisés par la majorité des packages traitant des données géospatiales). En particulier, les versions de ces différentes dépendances de l’application peuvent être précisément spécifiées, ce qui garantit la reproductibilité des calculs effectués. Une fois le <em>Dockerfile</em> correctement spécifié, une étape de construction (<em>build</em>) génère une image, c’est-à-dire une forme empaquetée et compressée de l’environnement qui permet de lancer l’application à l’identique. Les images créées de cette manière sont portables : elles peuvent être facilement distribuées — via un registre d’images, comme celui de GitLab à l’Insee — et exécutées de manière reproductible sur n’importe quelle infrastructure disposant d’un moteur de conteneurisation. L’exécution de l’image donne naissance à un conteneur, c’est à dire une instance vivante et déployée de l’application contenue dans l’image.</p>
<p>Outre le passage à l’échelle et l’autonomie, ces choix architecturaux favorisent également la reproductibilité des calculs statistiques. Le concept de reproductibilité — à savoir la capacité de reproduire le résultat d’une expérience en appliquant la même méthodologie aux mêmes données — est un critère fondamental de validité scientifique <span class="citation" data-cites="mcnutt2014reproducibility">(<a href="#ref-mcnutt2014reproducibility" role="doc-biblioref">McNutt 2014</a>)</span>. Il est également essentiel dans le domaine des statistiques publiques, car il constitue un facteur de transparence, essentielle pour établir et maintenir la confiance du public <span class="citation" data-cites="eurocodepractice2018">(<a href="#ref-eurocodepractice2018" role="doc-biblioref">European Commission, n.d.</a>)</span>. Favoriser la reproductibilité dans la production statistique implique de concevoir des solutions de traitement capables de produire des statistiques reproductibles, tout en étant partageables entre pairs <span class="citation" data-cites="ntts2019reproducibility">(<a href="#ref-ntts2019reproducibility" role="doc-biblioref">Luhmann et al. 2019</a>)</span>. Les infrastructures informatiques traditionnelles — qu’il s’agisse d’un ordinateur personnel ou d’une infrastructure partagée avec un accès à distance — sont limitées à cet égard. Construire un projet ou calculer un indicateur statistique dans ces environnements implique généralement une série d’étapes manuelles (installation des bibliothèques système, des binaires du langage de programmation, des packages du projet, gestion des versions conflictuelles, etc.) qui ne peuvent pas être pleinement reproduites du fait de la persistence de l’environnement sous-jacent. En comparaison, les conteneurs sont reproductibles par construction : leur processus de construction implique de définir précisément toutes les ressources nécessaires sous la forme d’un ensemble d’opérations standardisées, allant de la machine quasi-nue à l’application en cours d’exécution <span class="citation" data-cites="moreau2023containers">(<a href="#ref-moreau2023containers" role="doc-biblioref">Moreau, Wiebels, and Boettiger 2023</a>)</span>. De plus, ces environnements reproductibles peuvent être facilement partagés avec des pairs en les publiant sur des registres ouverts (par exemple, un registre de conteneurs comme DockerHub ou celui de GitLab) en plus du code source de l’application (par exemple, sur une forge logicielle comme GitHub ou GitLab). Cette approche améliore considérablement la réutilisation des projets de données, favorisant un modèle de développement et d’innovation basé sur la collaboration communautaire.</p>



</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-abdelaziz2023optimizing" class="csl-entry" role="listitem">
Abdelaziz, Abdullah I, Kent A Hanson, Charles E Gaber, and Todd A Lee. 2023. <span>“Optimizing Large Real-World Data Analysis with Parquet Files in r: A Step-by-Step Tutorial.”</span> <em>Pharmacoepidemiology and Drug Safety</em>.
</div>
<div id="ref-bentaleb2022containerization" class="csl-entry" role="listitem">
Bentaleb, Ouafa, Adam SZ Belloum, Abderrazak Sebaa, and Aouaouche El-Maouhab. 2022. <span>“Containerization Technologies: Taxonomies, Applications and Challenges.”</span> <em>The Journal of Supercomputing</em> 78 (1): 1144–81.
</div>
<div id="ref-chaudhuri1997overview" class="csl-entry" role="listitem">
Chaudhuri, Surajit, and Umeshwar Dayal. 1997. <span>“An Overview of Data Warehousing and OLAP Technology.”</span> <em>ACM Sigmod Record</em> 26 (1): 65–74.
</div>
<div id="ref-dean2008mapreduce" class="csl-entry" role="listitem">
Dean, Jeffrey, and Sanjay Ghemawat. 2008. <span>“MapReduce: Simplified Data Processing on Large Clusters.”</span> <em>Communications of the ACM</em> 51 (1): 107–13.
</div>
<div id="ref-dondon2023quels" class="csl-entry" role="listitem">
Dondon, Alexis, and Pierre Lamarche. 2023. <span>“Quels Formats Pour Quelles Donn<span>é</span>es?”</span> <em>Courrier Des Statistiques</em>, 86–103.
</div>
<div id="ref-eurocodepractice2018" class="csl-entry" role="listitem">
European Commission. n.d. <span>“European Statistics Code of Practice — Revised Edition 2017.”</span> <a href="https://ec.europa.eu/eurostat/web/products-catalogues/-/ks-02-18-142" class="uri">https://ec.europa.eu/eurostat/web/products-catalogues/-/ks-02-18-142</a>.
</div>
<div id="ref-parquet2013" class="csl-entry" role="listitem">
Foundation, Apache Software. 2013. <span>“Apache Parquet.”</span> <a href="https://parquet.apache.org/" class="uri">https://parquet.apache.org/</a>.
</div>
<div id="ref-ghemawat2003google" class="csl-entry" role="listitem">
Ghemawat, Sanjay, Howard Gobioff, and Shun-Tak Leung. 2003. <span>“The Google File System.”</span> In <em>Proceedings of the Nineteenth ACM Symposium on Operating Systems Principles</em>, 29–43.
</div>
<div id="ref-leclair2019utiliser" class="csl-entry" role="listitem">
Leclair, Marie et al. 2019. <span>“Using Scanner Data to Calculate the Consumer Price Index.”</span> <em>Courrier Des Statistiques</em> 3: 61–75.
</div>
<div id="ref-leite2019survey" class="csl-entry" role="listitem">
Leite, Leonardo, Carla Rocha, Fabio Kon, Dejan Milojicic, and Paulo Meirelles. 2019. <span>“A Survey of DevOps Concepts and Challenges.”</span> <em>ACM Computing Surveys (CSUR)</em> 52 (6): 1–35.
</div>
<div id="ref-li2020big" class="csl-entry" role="listitem">
Li, Yun, Manzhu Yu, Mengchao Xu, Jingchao Yang, Dexuan Sha, Qian Liu, and Chaowei Yang. 2020. <span>“Big Data and Cloud Computing.”</span> <em>Manual of Digital Earth</em>, 325–55.
</div>
<div id="ref-ntts2019reproducibility" class="csl-entry" role="listitem">
Luhmann, Sybille, Jacopo Grazzini, Fabio Ricciato, Mátyás Mészáros, Jean-Marc Museux, and Martina Hahn. 2019. <span>“Promoting Reproducibility-by-Design in Statistical Offices.”</span> In <em>2019 New Techniques and Technologies for Statistics (NTTS) Conference</em>. <a href="https://doi.org/10.5281/zenodo.3240198">https://doi.org/10.5281/zenodo.3240198</a>.
</div>
<div id="ref-mcnutt2014reproducibility" class="csl-entry" role="listitem">
McNutt, Marcia. 2014. <span>“Reproducibility.”</span> <em>Science</em> 343 (6168): 229–29.
</div>
<div id="ref-moreau2023containers" class="csl-entry" role="listitem">
Moreau, David, Kristina Wiebels, and Carl Boettiger. 2023. <span>“Containers for Computational Reproducibility.”</span> <em>Nature Reviews Methods Primers</em> 3 (1): 50.
</div>
<div id="ref-samundiswary2017object" class="csl-entry" role="listitem">
Samundiswary, S, and Nilma M Dongre. 2017. <span>“Object Storage Architecture in Cloud for Unstructured Data.”</span> In <em>2017 International Conference on Inventive Systems and Control (ICISC)</em>, 1–6. IEEE.
</div>
<div id="ref-Tigani_2023" class="csl-entry" role="listitem">
Tigani, Jordan. 2023. <span>“Big Data Is Dead.”</span> <a href="https://motherduck.com/blog/big-data-is-dead/">https://motherduck.com/blog/big-data-is-dead/</a>.
</div>
<div id="ref-vano2023cloud" class="csl-entry" role="listitem">
Vaño, Rafael, Ignacio Lacalle, Piotr Sowiński, Raúl S-Julián, and Carlos E Palau. 2023. <span>“Cloud-Native Workload Orchestration at the Edge: A Deployment Review and Future Directions.”</span> <em>Sensors</em> 23 (4): 2215.
</div>
<div id="ref-zhang2018comparative" class="csl-entry" role="listitem">
Zhang, Qi, Ling Liu, Calton Pu, Qiwei Dou, Liren Wu, and Wei Zhou. 2018. <span>“A Comparative Study of Containers and Virtual Machines in Big Data Environment.”</span> In <em>2018 IEEE 11th International Conference on Cloud Computing (CLOUD)</em>, 178–85. IEEE.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/inseefrlab\.github\.io\/DT-cloud-prod-stat\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      const annoteTargets = window.document.querySelectorAll('.code-annotation-anchor');
      for (let i=0; i<annoteTargets.length; i++) {
        const annoteTarget = annoteTargets[i];
        const targetCell = annoteTarget.getAttribute("data-target-cell");
        const targetAnnotation = annoteTarget.getAttribute("data-target-annotation");
        const contentFn = () => {
          const content = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          if (content) {
            const tipContent = content.cloneNode(true);
            tipContent.classList.add("code-annotation-tip-content");
            return tipContent.outerHTML;
          }
        }
        const config = {
          allowHTML: true,
          content: contentFn,
          onShow: (instance) => {
            selectCodeLines(instance.reference);
            instance.reference.classList.add('code-annotation-active');
            window.tippy.hideAll();
          },
          onHide: (instance) => {
            unselectCodeLines();
            instance.reference.classList.remove('code-annotation-active');
          },
          maxWidth: 300,
          delay: [50, 0],
          duration: [200, 0],
          offset: [5, 10],
          arrow: true,
          appendTo: function(el) {
            return el.parentElement.parentElement.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'quarto',
          placement: 'right',
          popperOptions: {
            modifiers: [
            {
              name: 'flip',
              options: {
                flipVariations: false, // true by default
                allowedAutoPlacements: ['right'],
                fallbackPlacements: ['right', 'top', 'top-start', 'top-end', 'bottom', 'bottom-start', 'bottom-end', 'left'],
              },
            },
            {
              name: 'preventOverflow',
              options: {
                mainAxis: false,
                altAxis: false
              }
            }
            ]        
          }      
        };
        window.tippy(annoteTarget, config); 
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../src/introduction/index.html" class="pagination-link" aria-label="1 - Introduction">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">1 - Introduction</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../src/implementation/index.html" class="pagination-link" aria-label="3 - Implémentation">
        <span class="nav-page-text">3 - Implémentation</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>